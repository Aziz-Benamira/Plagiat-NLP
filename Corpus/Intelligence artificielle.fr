L'intelligence artificielle (IA) est un ensemble de theories et de techniques visant a realiser des machines capables de simuler l'intelligence humaine.
Souvent classee dans le domaine des mathematiques et des sciences cognitives, l'IA fait appel a des disciplines telles que la neurobiologie computationnelle (qui a notamment inspire les reseaux neuronaux artificiels), les statistiques, ou l'algebre lineaire. Elle vise a resoudre des problemes a forte complexite logique ou algorithmique. Par extension, dans le langage courant, l'IA inclut les dispositifs imitant ou remplacant l'homme dans certaines mises en uvre de ses fonctions cognitives.
Les applications de l'IA comprennent notamment les moteurs de recherche, les systemes de recommandation, l'aide au diagnostic medical, la comprehension du langage naturel, les voitures autonomes, les chatbots, les outils de generation d'images, les outils de prise de decision automatisee, les programmes competitifs dans des jeux de strategie et certains personnages non-joueurs de jeu video.
Depuis l'apparition du concept, les finalites, les enjeux et le developpement de l'IA suscitent de nombreuses interpretations, fantasmes ou inquietudes, que l'on retrouve dans les recits ou films de science-fiction, dans les essais philosophiques ainsi que parmi des economistes.

Definition
Le terme  intelligence artificielle , souvent abrege par le sigle  IA  (ou  AI  en anglais, pour artificial intelligence) a ete cree par John McCarthy, qui l'a defini comme :  la science et l'ingenierie de la fabrication de machines intelligentes, en particulier de programmes informatiques intelligents. Elle est liee a la tache similaire qui consiste a utiliser des ordinateurs pour comprendre l'intelligence humaine, mais l'IA ne doit pas se limiter aux methodes qui sont biologiquement observables .
Pour Marvin Lee Minsky, l'un de ses createurs, l'IA est  la construction de programmes informatiques qui s'adonnent a des taches qui sont, pour l'instant, accomplies de facon plus satisfaisante par des etres humains car elles demandent des processus mentaux de haut niveau tels que : l'apprentissage perceptuel, l'organisation de la memoire et le raisonnement critique ,. Cette definition combine l'aspect  artificiel  des ordinateurs et des processus informatiques, aux aspects  intelligents  d'imitation de comportements humains, notamment de raisonnement et d'apprentissage. Celui-ci est a l'uvre dans les jeux, dans la pratique des mathematiques, dans la comprehension du langage naturel, dans la perception visuelle (interpretation des images et des scenes), auditive (comprehension du langage parle) ou par d'autres capteurs, dans la commande d'un robot dans un milieu inconnu ou hostile.
Avant les annees 2000, d'autres definitions sont proches de celle de Minsky, mais varient sur deux points fondamentaux :

les definitions qui lient l'IA a un aspect humain de l'intelligence et celles qui la lient a un modele ideal d'intelligence, non forcement humaine, nommee rationalite ;
les definitions qui insistent sur le fait que l'IA a pour but d'avoir toutes les apparences de l'intelligence (humaine ou rationnelle), et celles qui insistent sur le fait que le fonctionnement interne du systeme d'IA doit ressembler egalement a celui de l'etre humain et etre au moins aussi rationnel.

Le grand public confond souvent l'intelligence artificielle avec l'apprentissage automatique (machine learning) et l'apprentissage profond (deep learning). Ces trois notions different et sont en realite imbriquees : l'intelligence artificielle englobe l'apprentissage automatique, qui lui-meme englobe l'apprentissage profond.
Les definitions font souvent intervenir, :

une capacite a percevoir l'environnement et a prendre en compte la complexite du monde reel ;
un traitement de l'information (collecter et interpreter des intrants, captes sous forme de donnees) ;
des prises de decision (y compris dans le raisonnement et l'apprentissage), choix d'actions, execution de taches (dont d'adaptation, de reaction aux changements de contexte), avec un certain niveau d'autonomie ;
la realisation d'objectifs specifiques (raison ultime des systemes d'IA).
Le groupe AI Watch note que les IA peuvent aussi etre classees en fonction des familles dalgorithmes et/ou des modeles theoriques qui les sous-tendent, des capacites cognitives reproduites par lIA, des fonctions executees par lIA. Les applications de lIA peuvent, elles, etre classees en fonction du secteur socioeconomique et/ou des fonctions qu'elles y remplissent.

Techniques
Apprentissage automatique
L'apprentissage automatique consiste a permettre au modele d'IA d'apprendre a effectuer une tache au lieu de specifier exactement comment il doit l'accomplir. Le modele contient des parametres dont les valeurs sont ajustees tout au long de l'apprentissage. La methode de la retropropagation du gradient est capable de detecter, pour chaque parametre, dans quelle mesure il a contribue a une bonne reponse ou a une erreur du modele, et peut l'ajuster en consequence. L'apprentissage automatique necessite un moyen d'evaluer la qualite des reponses fournies par le modele. Les principales methodes d'apprentissage sont :

Apprentissage supervise
Un jeu de donnees annote est utilise pour entrainer l'algorithme. Il contient des donnees d'entree fournies au modele et les reponses correspondantes attendues, que le modele est entraine a produire. Il est parfois difficile de se procurer suffisamment de donnees annotees avec les reponses attendues.
Apprentissage non supervise
Un jeu de donnees est fourni au modele, mais n'est pas annote avec les reponses attendues. Le but peut par exemple etre de regrouper les donnees similaires entre elles (clustering).
Apprentissage auto-supervise
Un probleme d'apprentissage supervise est automatiquement genere a partir d'un jeu de donnees non annote. Cela fonctionne souvent en cachant une partie des informations (des mots d'un texte, des morceaux d'images) afin d'entrainer le modele a les predire.
Apprentissage par renforcement
L'agent est plonge dans un environnement ou ce qu'il fait est evalue. Par exemple, un agent peut apprendre a jouer aux echecs en jouant contre lui-meme, et le resultat (victoire ou defaite) permet a chaque iteration d'evaluer s'il a bien joue. Il n'y a dans ce cas pas besoin de jeu de donnees.

Reseaux de neurones
Les reseaux de neurones artificiels sont inspires du fonctionnement du cerveau humain : les neurones sont en general connectes a d'autres neurones en entree et en sortie. Les neurones d'entree, lorsqu'ils sont actives, agissent comme s'ils participaient a un vote pondere pour determiner si un neurone intermediaire doit etre active et ainsi transmettre un signal vers les neurones de sortie. En pratique, pour l'equivalent artificiel, les  neurones d'entree  ne sont que des nombres et les poids de ce  vote pondere  sont des parametres ajustes lors de l'apprentissage,.
Hormis la fonction d'activation, les reseaux de neurones artificiels n'effectuent en pratique que des additions et des multiplications matricielles, ce qui fait qu'ils peuvent etre acceleres par l'utilisation de processeurs graphiques. En theorie, un reseau de neurones peut approximer n'importe quelle fonction.
Pour de simples reseaux de neurones a propagation avant (feedforward en anglais), le signal ne passe que dans une direction. Avec les reseaux de neurones recurrents, le signal de sortie de chaque neurone est reinjecte en entree de ce neurone, permettant dimplementer un mecanisme de memoire a court terme. Les reseaux neuronaux convolutifs, qui sont particulierement utilises en traitement d'images, introduisent une notion de localite. Leurs premieres couches identifient des motifs relativement basiques et locaux comme des contours, la ou les dernieres couches traitent de motifs plus complexes et globaux.

Apprentissage profond
L'apprentissage profond (deep learning en anglais) utilise de multiples couches de neurones entre les entrees et les sorties, d'ou le terme  profond . L'utilisation de processeurs graphiques pour accelerer les calculs et l'augmentation des donnees disponibles a contribue a la montee en popularite de l'apprentissage profond. Il est utilise notamment en vision par ordinateur, en reconnaissance automatique de la parole et en traitement automatique des langues (ce qui inclut les grands modeles de langage).

Grands modeles de langages
Les grands modeles de langage sont des modeles de langage ayant des milliards de parametres. Ils reposent tres souvent sur l'architecture transformeur.
Les transformeurs generatifs pre-entraines (Generative Pretrained Transformers ou GPT en anglais) sont un type particulierement populaire de grand modele de langage. Leur  pre-entrainement  consiste a predire, etant donnee une partie d'un texte, le token suivant (un token etant une sequence de caracteres, typiquement un mot, une partie d'un mot, ou de la ponctuation). Cet entrainement a predire ce qui va suivre, repete pour un grand nombre de textes, permet a ces modeles d'accumuler des connaissances sur le monde. Ils peuvent ensuite generer du texte semblable a celui ayant servi au pre-entrainement, en predisant un a un les tokens suivants. En general, une autre phase d'entrainement est ensuite effectuee pour rendre le modele plus veridique, utile et inoffensif. Cette phase d'entrainement (utilisant souvent une technique appelee RLHF) permet notamment de reduire un phenomene appele  hallucination , ou le modele genere des informations d'apparence plausible mais fausses.
Avant d'etre fourni au modele, le texte est decoupe en tokens. Ceux-ci sont convertis en vecteurs qui en encodent le sens ainsi que la position dans le texte. A l'interieur de ces modeles se trouve une alternance de reseaux de neurones et de couches d'attention. Les couches d'attention combinent les concepts entre eux, permettant de tenir compte du contexte et de saisir des relations complexes.
Ces modeles sont souvent integres dans des agents conversationnels, aussi appeles chatbots, ou le texte genere est formate pour repondre a l'utilisateur. Par exemple, l'agent conversationnel ChatGPT exploite les modeles GPT-3.5 et GPT-4. En 2023 font leur apparition des modeles grand public pouvant traiter simultanement differents types de donnees comme le texte, le son, les images et les videos, tel Google Gemini.

Recherche et optimisation
Certains problemes necessitent de chercher intelligemment parmi de nombreuses solutions possibles.

Recherche locale
La recherche locale, ou recherche par optimisation, repose sur l'optimisation mathematique pour trouver une solution numerique a un probleme, en ameliorant progressivement la solution choisie.
En particulier, en apprentissage automatique, la descente de gradient permet de trouver une solution localement optimale, etant donne une fonction de cout a minimiser en faisant varier les parametres du modele. Elle consiste, a chaque etape, a modifier les parametres a optimiser dans la direction qui permet de reduire le mieux la fonction de cout. La solution obtenue est localement optimale, mais il se peut qu'il y ait globalement de meilleures solutions, qui auraient pu etre obtenues avec differentes valeurs initiales de parametres. Les modeles d'IA modernes peuvent avoir des milliards de parametres a optimiser, et utilisent souvent des variantes plus complexes et efficaces de la descente de gradient.
Les algorithmes evolutionnistes, inspires de la theorie de l'evolution, utilisent une forme de recherche par optimisation. A chaque etape, des operations telles que la  mutation  ou le  croisement  sont effectuees de maniere aleatoire pour obtenir differentes variantes, et les variantes les mieux adaptees sont selectionnees pour l'etape suivante.

Recherche dans l'espace des etats
La recherche dans l'espace des etats vise a trouver un etat accomplissant l'objectif a travers un arbre des etats possibles. Par exemple, la recherche antagoniste est utilisee pour des programmes jouant a des jeux tels que les echecs ou le go. Elle consiste a parcourir l'arbre des coups possibles par le joueur et son adversaire, a la recherche d'un coup gagnant. La simple recherche exhaustive est rarement suffisante en pratique vu le nombre d'etats possibles. Des heuristiques sont utilisees pour prioriser les chemins les plus prometteurs.

Logique
La logique formelle est utilisee pour le raisonnement et la representation des connaissances. Elle se decline en deux principales formes, la logique propositionnelle et la logique predicative. La logique propositionnelle opere sur des affirmations qui sont vraies ou fausses, et utilise la logique connective avec des operateurs tels que  et ,  ou ,  non  et  implique . La logique predicative etend la logique propositionnelle et peut aussi operer sur des objets, predicats ou relations. Elle peut utiliser des quantificateurs comme dans  Chaque X est un Y  ou  Certains X sont des Y .
L'inference logique (ou deduction) est le processus qui consiste a fournir - a l'aide d'un moteur d'inference - une nouvelle affirmation (la conclusion) a partir d'autres affirmations connues comme etant vraies (les premisses). Une regle d'inference decrit les etapes valides d'une preuve ; la plus generale est la regle de resolution. L'inference peut etre reduite a la recherche d'un chemin amenant des premisses aux conclusions, ou chaque etape est une application d'une regle d'inference. Mais a part pour de courtes preuves dans des domaines restreints, la recherche exhaustive prend beaucoup de temps.
La logique floue assigne des valeurs de verite entre 0 et 1, permettant de gerer des affirmations vagues, comme  il fait chaud . La logique non monotone permet d'annuler certaines conclusions. Diverses autres formes de logique sont developpees pour decrire de nombreux domaines complexes.

Methodes probabilistes et gestion de l'incertitude
De nombreux problemes en IA (raisonnement, planification, apprentissage, perception, robotique, etc.) necessitent de pouvoir operer a partir d'informations incompletes ou incertaines.
Certaines techniques reposent sur l'inference bayesienne, qui fournit une formule pour mettre a jour des probabilites subjectives etant donnees de nouvelles informations. C'est notamment le cas des reseaux bayesiens. L'inference bayesienne necessite souvent d'etre approximee pour pouvoir etre calculee.
Les methodes de Monte-Carlo sont un ensemble de techniques pour resoudre des problemes complexes en effectuant aleatoirement de nombreuses simulations afin d'approximer la solution.
Les reseaux de neurones peuvent aussi etre optimises pour fournir des estimations probabilistes.

Des outils mathematiques precis ont ete developpes pour analyser comment des agents intelligents peuvent faire des choix et des plans en utilisant la theorie de la decision, la maximisation de l'esperance et la theorie de la valeur de l'information. Ces techniques comprennent des modeles tels que les processus de decision markoviens, la theorie des jeux et les mecanismes d'incitation.

Classifieurs et methodes statistiques
De nombreux modeles d'IA ont pour but d'assigner une categorie (classification), une valeur (regression) ou une action a des donnees fournies. Les methodes de classification comprennent arbres de decision, k plus proches voisins, machine a vecteurs de support ou classification bayesienne naive,. Les reseaux de neurones peuvent egalement faire de la classification.

Histoire
Comme precurseur a l'intelligence artificielle, divers automates ont ete crees au cours de l'histoire, dont le canard de Vaucanson ou les automates d'Al-Jazari. Certains automates remontent a l'Antiquite et etaient utilises pour des ceremonies religieuses. Des mythes et rumeurs rapportent egalement la creation d'etres intelligents, par exemple les golems.
Des philosophes et mathematiciens comme Raymond Lulle, Leibniz ou George Boole ont cherche a formaliser le raisonnement et la generation d'idees.
Au XXe siecle, Alan Turing a notamment invente un modele de calcul par la suite appele machine de Turing, explore la notion de calculabilite et d'intelligence des machines, et propose le  jeu de l'imitation  (test de Turing) pour evaluer l'intelligence de futures machines. Le terme  intelligence artificielle  a ete mis en avant par John McCarthy lors de la conference de Dartmouth en 1956, ou l'intelligence artificielle a ete etablie en tant que discipline a part entiere,. Dans les annees qui ont suivi, des chercheurs ont propose diverses preuves de concept, dans des situations specifiques, de ce que les machines peuvent faire en theorie. Par exemple, le programme ELIZA pouvait se faire passer pour un psychotherapeute, et le Logic Theorist pouvait demontrer des theoremes.
La fin du siecle a ete marquee par des periodes d'enthousiasme, et deux periodes de desillusion et de gel des financements appelees  hivers de l'IA , la premiere de 1974 a 1980 et la seconde de 1987 a 1993. 
Les systemes experts ont ete particulierement populaires dans les annees 1980, malgre leur fragilite et la difficulte a implementer manuellement les bonnes regles d'inferences. Des techniques d'apprentissage automatique se sont developpees (reseaux de neurones, retropropagation du gradient, algorithmes genetiques) ainsi que l'approche connexionniste. Mais les faibles puissances de calcul et le manque de donnees d'entrainement limitait leur efficacite. Certains domaines n'ont progressivement plus ete consideres comme faisant partie de l'intelligence artificielle, a mesure qu'une solution efficace etait trouvee ; un phenomene parfois appele  effet IA .

Les performances des ordinateurs s'accroissant continuellement. En 1996, pour la premiere fois, un supercalculateur a gagne plusieurs parties au jeu d'echec contre le champion du monde.
Dans les annees 2000, le Web 2.0, le big data et de nouvelles infrastructures et capacites de calcul ont permis l'exploration de masses de donnees sans precedent. En 2005, le projet Blue Brain a debute, ayant pour objectif de simuler le cerveau de mammiferes. En 2012, le reseau neuronal convolutif AlexNet a lance l'utilisation de processeurs graphiques pour entrainer des reseaux de neurones, decuplant ainsi les capacites de calcul dediees a l'apprentissage. La meme annee, un programme a gagne quatre des cinq parties de Go disputees contre le meilleur joueur du monde. Des organisations visant a creer une intelligence artificielle generale ont vu le jour, comme DeepMind en 2010 et OpenAI en 2015. Des les annees 2010, des outils d'intelligence artificielle (specialisee ou generative) ont accompli des progres spectaculaires, mais restent loin des performances du vivant dans beaucoup de ses aptitudes naturelles, en particulier sur son aptitude a apprendre rapidement a partir d'un faible volume d'information (par induction), selon le magazine Slate en 2019.
En 2017, des chercheurs de Google ont propose l'architecture transformeur, qui a servi de base aux grands modeles de langage. En 2018, Yann Le Cun, Yoshua Bengio et Geoffrey Hinton ont remporte le prix Turing pour leurs travaux sur l'apprentissage profond,.
En 2022, des programmes generant des images a partir de descriptions textuelles, comme Midjourney ou DALL-E 2, se sont popularises. La meme annee, l'agent conversationnel ChatGPT a connu une croissance inedite, gagnant un million d'utilisateurs en seulement cinq jours et cent millions d'utilisateurs en deux mois, ce qui a accentue un phenomene de  course  a l'IA. En 2023, les progres rapides de l'IA ont suscite des inquietudes quant a un potentiel risque d'extinction de l'humanite. Des modeles modeles de fondation  multimodaux , c'est-a-dire capables de traiter simultanement plusieurs modalites (texte, images, son) ont emerge, tels que Google Gemini et GPT-4o.

Intelligence artificielle generale
L'intelligence artificielle generale (IAG) comprend tout systeme informatique capable d'effectuer ou d'apprendre pratiquement n'importe quelle tache cognitive propre aux humains ou autres animaux. Elle peut alternativement etre definie comme un systeme informatique surpassant les humains dans la plupart des taches ayant un interet economique.
L'intelligence artificielle generale a longtemps ete consideree comme un sujet purement speculatif. Certains travaux de recherche ont deja decrit GPT-4 comme ayant des  etincelles  d'intelligence artificielle generale,. Les experts en intelligence artificielle affichent de larges desaccords et incertitudes quant a la date potentielle de conception des premieres intelligences artificielles generales (parfois appelees  intelligences artificielles de niveau humain ), leur impact sur la societe, et leur potentiel a declencher une  explosion d'intelligence .
Un sondage de 2022 suggere que 90 % des experts en IA pensent que l'IAG a plus d'une chance sur deux d'etre realisee dans les 100 ans, autour d'une date mediane de 2061.
Une superintelligence artificielle est un type hypothetique d'intelligence artificielle generale dont les capacites intellectuelles depasseraient de loin celles des humains les plus brillants. Le philosophe Nick Bostrom note que les machines disposent de certains avantages par rapport aux cerveaux humains, notamment en ce qui concerne la memoire, la vitesse (la frequence des processeurs etant de l'ordre de dix millions de fois plus elevee que celle des neurones biologiques) et la capacite a partager des connaissances.

Tests
Dans ce contexte, un test est un moyen d'evaluer les capacites d'une intelligence artificielle a imiter certains comportements et raisonnements humains.

Test de Turing
Dans le test de Turing, une machine et un humain repondent textuellement aux questions d'un interrogateur humain. L'interrogateur ne les voit pas mais doit determiner a partir des reponses textuelles lequel des deux est la machine. Pour passer le test, la machine doit parvenir une bonne partie du temps a tromper l'interrogateur. Ce test a ete concu par Alan Turing en 1950 dans l'article  Computing Machinery and Intelligence . Initialement appele le  jeu de l'imitation , son but etait de fournir une experience concrete pour determiner si les machines peuvent penser.

Test du cafe
Imagine par Steve Wozniak, le test du cafe consiste a placer un systeme intelligent dans un habitat americain moyen et a lui demander de faire un cafe. La reussite du test implique donc plusieurs taches comme l'orientation dans un environnement inconnu, deduire le fonctionnement d'une machine, trouver les ustensiles necessaires

Test de l'etudiant
Propose par Ben Goertzel, le test de l'etudiant evalue la capacite d'un robot a s'inscrire dans un etablissement d'enseignement superieur, suivre les cours, passer les examens et obtenir le diplome final.

Test de l'embauche
Propose par le chercheur Nils John Nilsson, le test de l'embauche consiste a faire postuler un systeme intelligent a un travail important pour l'economie, ou il doit travailler au moins aussi bien qu'un humain.

Personnalites
Prix Turing
Plusieurs prix Turing (ACM Turing Award) ont ete attribues a des pionniers de l'intelligence artificielle, notamment :

Marvin Minsky (1969) ;
John McCarthy (1971) ;
Allen Newell et Herbert Simon (1975) ;
Edward Feigenbaum et Raj Reddy (1994) ;
Judea Pearl (2011) ;
Yann Le Cun, Geoffrey Hinton et Yoshua Bengio (2019).

Autres personnalites
Claude Shannon, fondateur de la theorie de l'information, inventeur de la porte logique, concepteur de programmes d'echecs.
Rodney Brooks, un roboticien australien.
Demis Hassabis, cofondateur et PDG de DeepMind.
Ian Goodfellow, inventeur des reseaux antagonistes generatifs.
Andrew Ng, connu comme directeur scientifique de Baidu et comme createur de Coursera.
Terry Winograd, pionnier en traitement automatique des langues.
Vladimir Vapnik, co-inventeur des machines a vecteurs de support.
Seymour Papert, ancien directeur du Laboratoire d'intelligence artificielle du MIT.
Jacques Pitrat, pionnier francais en intelligence artificielle symbolique.
En 2023, le magazine Time publie une liste de 100 personnalites influentes du domaine de l'IA et leurs biographies.

Domaines d'application
Les usages principaux qu'a successivement permis l'IA sont :

la recherche, l'analyse statistique, l'interpretation, le diagnostic d'une certaine realite[Quoi ?] sur la base de quantites croissantes de donnees d'abord textuelles, puis de photos, de videos et d'enregistrements sonores, collectes via le reseau Internet et par la capture de l'activite des internautes et autres utilisateurs de produits telephoniques et informatiques ;
la generation de contenus de plus en plus realistes, vraisemblables ou non, permettant d'alimenter des discours apparemment documentes et de creer des images ou des sons inspires du reel.
L'IA permet d'effectuer differents types de taches, dont :

le partitionnement et la classification automatique ;
la reconnaissance de formes, des visages et la vision en general, etc. ;
l'integration automatique d'informations provenant de sources heterogenes (fusion de donnees) ;
l'aide aux diagnostics et a la decision ;
l'assistance par des machines dans les taches dangereuses, ou demandant une grande precision ;
l'automatisation de taches ;
le traitement automatique des langues, notamment la traduction automatique, si possible en temps reel ou tres legerement differe ;
la reconnaissance automatique de la parole (conversion de parole en texte) et le dialogue automatique : se faire comprendre en lui parlant ;
le raisonnement automatique (voir Systeme expert) ;
la composition musicale automatique (voir les travaux de Rene-Louis Baron et de l'Ircam ; vers 2016, les recherches de Francois Pachet portent le developpement de flow machines telles que Deepbach,) ;
l'emotion artificielle (voir les travaux de Rosalind Picard sur l'emotion) et l'eventualite d'une subjectivite artificielle ;
la resolution de problemes complexes, tels que les problemes d'allocation de ressources.
En combinant differents algorithmes, on est passe en quelques annees de la reconnaissance de l'ecriture manuscrite sur des formulaires de cheques bancaires (annees 1990) a l'optimisation d'itineraires entre deux ou plusieurs points, tenant compte des voies disponibles, de la longueur et de la vitesse probable sur chacun des segments, du moyen de locomotion et de souhaits particuliers (eviter les peages, points de passage obliges, caracteristiques touristiques, etc.), puis a la reconnaissance automatisee de documents dactylographies ou manuscrits, permettant ensuite de les classer selon leur nature avant de les transmettre a des agents specialises, humains ou automates, capables d'y apporter la suite appropriee (reponses predefinies ou declenchement d'une chaine de traitements). Lorsque les algorithmes ne parviennent pas a interpreter les donnees avec un degre suffisant de certitude, ils sont generalement soumis a des humains. Entre alors en jeu l'apprentissage : en correlant les caracteristiques des donnees accumulees et des interpretations apportees ou corrigees par les agents humains, l'IA ameliore progressivement ses facultes d'analyse jusqu'a ce que ses predictions soient suffisamment fiables pour qu'il ne soit plus necessaire de les faire verifier par un humain. Il en va de meme pour la plupart des situations ou l'IA, par ses performances et son cout, surpasse l'humain dans l'analyse de textes, d'images fixes ou animees, d'enregistrements sonores, de donnees scientifiques, commerciales ou industrielles. L'accroissement des performances conjuguees du materiel et des algorithmes permet en outre de traiter en temps reels les flux de donnees comme la voix humaine et les images de cameras, ouvrant ainsi la voie a la traduction simultanee, la transcription textuelle, l'identification des individus, la detection de comportements anormaux ou illegaux, voire le dialogue avec des humains.
L'intelligence artificielle est desormais utilisee dans de nombreux domaines. Ses capacites permettent notamment d'automatiser et d'optimiser des taches complexes, de traiter et d'analyser de vastes quantites de donnees, et d'ameliorer la prise de decision. L'adoption de l'intelligence artificielle est en forte expansion dans les annees 2020, stimulee par les avancees en intelligence artificielle generative, en particulier dans les grands modeles de langage, dont la polyvalence ouvre la voie a de nouveaux cas d'usage, ainsi que dans les domaines de la programmation informatique (generation de code), de l'image et du son  (photos et videos de synthese, animation du visage en association avec la synthese vocale) et dans la prevention et l'attenuation des risques (diagnostic medical, situations de crise, accidents industriels, catastrophes naturelles, etc.).

Finance et banques
Plusieurs grands noms de la finance se sont montrees interessees par de telles technologies, avec des projets comme ceux de Bridgewater Associates ou une intelligence artificielle va gerer entierement un fonds ou encore la plateforme d'analyse predictive Sidetrade.
Sont egalement developpes des systemes de trading algorithmique, dont les gains de vitesses permis par l'automatisation peuvent leur donner un avantage par rapport a des traders humains, en particulier grace au trading a haute frequence.

Militaire
Le domaine militaire utilise de plus en plus l'intelligence artificielle, notamment pour le pilotage automatique, le guidage de missiles, l'identification, le commandement, l'aide a la decision, la cyberguerre et la cyberdefense, ou pour la documentation et les processus administratifs.
Cette course aux armements est notamment illustree par le projet Maven aux Etats-Unis. Des 2015, une IA nommee ALPHA a  systematiquement triomphe d'un pilote de chasse chevronne . En 2018, l'ONU a tente d'interdire les systemes d'armes letales autonomes  avant qu'il ne soit trop tard , mais peine encore en janvier 2024 a etablir le moindre cadre legal international face aux reticences, notamment de la Russie, des Etats-Unis et d'Israel, dont le veto peut bloquer une proposition. Des drones tueurs pilotes par intelligence artificielle ont ete utilises lors du conflit ukraino-russe. Le 10 janvier 2024, OpenAI a modifie ses conditions d'utilisation ; il continue d'interdire l'usage de ses services tels que ChatGPT a des fins illegales ou de destruction des biens, mais n'interdit plus explicitement les usages militaires. L'intelligence artificielle generative est parfois utilisee par les institutions militaires pour rediger plus vite la documentation, mais son adoption est limitee par la confidentialite des donnees, les reglementations, ou le risque d'erreur et le besoin de verification.
En France, la force operationnelle IA du ministere des Armees rend en septembre 2019 un rapport detaillant sa strategie, qui inclut la creation d'une Cellule de coordination de l'intelligence artificielle de defense (CCIAD) rattachee a l'Agence de l'innovation de defense. La loi de programmation militaire prevoit un budget de 700 millions d'euros pour les missions en faveur de l'IA, soit une moyenne de 100 millions par an. La France est opposee aux armes pouvant attaquer des cibles de facon completement autonome, estimant qu'il est au moins necessaire de conserver une supervision humaine,.
Dans le cadre de la guerre Israel-Hamas de 2023-2024, Israel a utilise deux systemes d'IA pour generer des cibles a frapper : Habsora (soit  l'evangile ) a ete utilise pour dresser une liste de batiments a cibler, tandis que Lavander a produit une liste de 37 000 personnes a cibler,. La liste des batiments comprenait les maisons privees a Gaza de personnes soupconnees d'etre affiliees a des membres du Hamas. Les responsables de Tsahal affirment que le programme repond au probleme anterieur du manque de cibles de larmee de lair. Auparavant, Tsahal etait en mesure d'identifier 50 cibles par an, tandis que le programme en produit 100 par jour. La combinaison de la technologie de ciblage de lIA et du changement de politique consistant a eviter les cibles civiles a entraine un nombre sans precedent de morts civils palestiniens,.

Medecine
La medecine a aussi vu de grands progres grace a l'utilisation de systemes d'aide au diagnostic ou de diagnostic automatise.
En 2018, Google DeepMind, filiale de Google specialisee dans la recherche avancee en intelligence artificielle, a publie les resultats d'une experimentation d'intelligence artificielle pouvant detecter les maladies oculaires. Les resultats indiquent que l'IA le fait avec une marge d'erreur plus faible que les ophtalmologues.
Google DeepMind a egalement concu AlphaFold, un systeme d'intelligence artificielle utilisant l'apprentissage profond qui permet de predire la facon dont des proteines se replient. Les proteines sont composees de chaines d'acides amines et la facon dont elles se replient determine leur fonction. Cette nouvelle methode, introduite en 2018 et amelioree en 2020, est nettement plus rapide que les approches traditionnelles et a ete decrite comme une revolution dans le domaine de la recherche en biologie,.
La France cree en 2019 le Health Data Hub afin d'encadrer et de faciliter l'utilisation des donnees de sante dans la recherche.
En 2023, la version de ChatGPT reposant sur GPT-4 s'est montree facilement capable d'obtenir le diplome de medecin aux Etats-Unis.
L'intelligence artificielle (IA) est de plus en plus utilisee dans le domaine medical, transformant les pratiques cliniques et facilitant le diagnostic, le traitement et la gestion des maladies. Les algorithmes d'apprentissage automatique, un sous-ensemble de l'IA, analysent de grandes quantites de donnees medicales pour en extraire des modeles et des tendances. Cette capacite d'analyse a permis des avancees significatives dans le diagnostic precoce de maladies comme le cancer et les maladies cardiaques, ou les systemes bases sur l'IA peuvent detecter des anomalies a partir d'images medicales avec une precision parfois superieure a celle des praticiens humains.
Un des domaines ou l'IA s'avere particulierement efficace est celui de l'imagerie medicale. Des outils comme les reseaux de neurones convolutifs sont utilises pour analyser les radiographies, les IRM et autres types d'imageries, permettant de reperer les signes precoces de pathologies complexes. Par exemple, une etude menee par McKinney et al. (2020) a demontre que l'IA pouvait reduire les faux positifs et negatifs dans le depistage du cancer du sein, ameliorant ainsi la precision et la rapidite du diagnostic.
De plus, l'IA joue un role cle dans la medecine personnalisee, ou elle aide a adapter les traitements en fonction des caracteristiques genetiques et biologiques des patients. Grace a l'analyse des donnees genomiques, les medecins peuvent elaborer des therapies specifiques pour des maladies comme le cancer ou les maladies genetiques rares. L'IA facilite egalement le developpement de nouveaux medicaments, en identifiant des molecules potentielles pour le traitement de certaines maladies, un processus qui necessitait auparavant plusieurs annees.
Cependant, malgre ses promesses, l'usage de l'IA en medecine souleve des questions ethiques et de securite, notamment en ce qui concerne la protection des donnees des patients et la transparence des algorithmes. La Food and Drug Administration (FDA) aux Etats-Unis et d'autres organismes reglementaires travaillent a definir des cadres pour encadrer l'utilisation securisee et ethique de l'IA dans les soins de sante.

Renseignement policier
Un usage de l'IA se developpe dans le domaine de la prevention des crimes et delits. La police britannique, par exemple, developpe une IA de ce genre, annoncee comme pouvant etre operationnelle des mars 2019. Baptisee National Data Analytics Solution (Solution nationale d'analyse de donnees ou NDAS), elle repose sur l'IA et des statistiques et vise a estimer le risque qu'une personne commette un crime ou en soit elle-meme victime, pour orienter les services sociaux et medicaux qui peuvent la conseiller.
L'usage d'outils de prediction des crimes a partir des donnees prealablement existantes est toutefois l'objet de controverses, compte tenu des biais sociaux (notamment raciaux) qu'il comporte. En effet, la logique d'identification de schemas propre a ces technologies joue un role de renforcement des prejuges deja existants.

Cybercrime
L'intelligence artificielle (IA) est de plus en plus exploitee dans le domaine du cybercrime, comme le revele une etude de la societe specialisee en cybersecurite SlashNext. Cette tendance croissante a l'utilisation de l'IA pour commettre des crimes en ligne montre une sophistication accrue des attaques. L'entreprise SlashNext a notamment identifie l'usage de deux IA malicieuses, FraudGPT et WormGPT, tout en suggerant que ces decouvertes ne representent que la partie visible d'une menace potentiellement colossale. Lors de leurs investigations, les chercheurs ont egalement mis en lumiere l'existence de DarkBart et DarkBert, deux chatbots malveillants en developpement, capables d'integrer la technologie de reconnaissance d'images de Google Google Lens. Ces chatbots pourraient envoyer du texte et des images, et participer a des attaques d'ingenierie sociale avancees. Face a cette menace croissante, les solutions actuelles de lutte contre le cybercrime semblent insuffisantes, estime un rapport d'Immunefi, qui souligne les limites de certaines IA, telles que ChatGPT, dans la detection des exploits.

Droit
Le droit fait appel a l'IA dans la perspective de predire les decisions de justice, d'aider a la decision et de trancher les cas simples. L'Estonie a par exemple developpe une intelligence artificielle capable de prendre des decisions de justice sur des delits mineurs. Les Etats-Unis utilisent par ailleurs dans certaines juridictions le systeme COMPAS (en)(Correctional Offender Management profiling for Alternative Sanctions), un systeme d'aide a la prise de decision pour les juges. Plusieurs startups se sont specialisees dans ce creneau, creant le domaine de la legaltech.

Logistique et transports
Le domaine de la logistique a vu certains projets utilisant de l'intelligence artificielle se developper notamment pour la gestion de la chaine logistique (supply chain) ou des problematiques de livraison telle celle du dernier kilometre.
L'intelligence artificielle est egalement fortement utilisee dans le domaine des transports en commun, car elle permet de faciliter la regulation et la gestion du trafic au sein de reseaux de plus en plus complexes, comme le systeme UrbanLoop en cours d'etude dans la ville de Nancy.
Meme si les problemes d'optimisation de temps de trajet ou de transports font partie des plus anciennes applications de solutions a base d'intelligence artificielle (voir le probleme du voyageur de commerce ou l'algorithme de Dijkstra), les avancees recentes, notamment en apprentissage profond, ont permis des progres significatifs en matiere de precision. Certains projets comme Google Maps utilisent par exemple des systemes d'IA en milieu urbain pour compenser la reflexion du signal GPS sur les immeubles avoisinants, ou pour cartographier des zones ou peu d'informations sont disponibles,.
Plusieurs entreprises ont par ailleurs annonce avoir developpe des programmes de recherche en voiture autonome, notamment Google a travers sa filiale Waymo, l'entreprise francaise Navya ou encore Tesla.

Industrie
Les systemes intelligents deviennent monnaie courante dans de nombreuses industries. Plusieurs taches peuvent leur etre confiees, notamment celles considerees comme trop dangereuses pour un humain. Certains applications se concentrent sur les systemes de maintenance predictive, permettant des gains de performance grace a une detection des problemes de production en amont.

Robotique
La robotique a recours a l'intelligence artificielle a plusieurs egards, notamment pour la perception de l'environnement (objets et visages), l'apprentissage et l'intelligence artificielle developpementale,.
L'interaction homme-robot manque encore souvent de naturel et est un enjeu de la robotique. Il s'agit de permettre aux robots d'evoluer dans le monde dynamique et social des humains et d'echanger avec eux de facon satisfaisante. L'echange necessite egalement, a l'inverse, une evolution du regard que les humains portent sur les robots ; selon Veronique Auberge, chercheuse a l'Universite Grenoble-Alpes  la vraie revolution n'est pas technologique, elle est culturelle . D'ores et deja, a travers les robots dotes d'intelligence artificielle, tel Google Home, les utilisateurs combleraient un isolement social.

Jeux video
L'intelligence artificielle est par exemple utilisee pour animer les personnages non-joueurs de jeux video, qui sont concus pour servir d'opposants, d'aides ou d'accompagnants lorsque des joueurs humains ne sont pas disponibles ou desires. Differents niveaux de complexite sont developpes, d'une simple assistance a un comportement complexe imitant (ou depassant) les meilleurs joueurs humains.

Art
Des la fin des annees 1980, des artistes s'emparent de l'intelligence artificielle pour donner un comportement autonome a leurs uvres. Les Francais Michel Bret, Edmond Couchot et Marie-Helene Tramus sont des pionniers, ainsi qu'en temoignent des uvres comme La Plume et Le Pissenlit (1988), puis La Funambule (2000), animee par un reseau de neurones. L'Americain Karl Sims, en partenariat avec la societe Thinking Machines, cree en 1993 Genetic Images, machines incorporant[Comment ?] des algorithmes genetiques. Le couple franco-autrichien Christa Sommerer et Laurent Mignonneau cree depuis le debut des annees 1990 de nombreuses uvres dans le champ de la vie artificielle, parmi lesquelles Interactive plant growing (1992) ou A-Volve (1994)[ref. necessaire]. Le Francais Florent Aziosmanoff propose quant a lui de considerer que l'emploi de l'intelligence artificielle dans l'art conduit a l'emergence d'une nouvelle discipline d'expression, qu'il nomme le Living art.
Le 23 octobre 2018, la societe de vente aux encheres Christie's met en vente le tableau Portrait d'Edmond de Belamy realise par une intelligence artificielle a l'aide de reseaux antagonistes generatifs. La peinture est signee par la formule mathematique a l'origine de sa creation ( Min (G) max (D) Ex [log (D(x))] + Ez [log(1-D(G(z)))] ). Cette vente souleve de nombreux debats sur son statut de creation artistique et sur l'auteur de l'uvre : il peut etre l'intelligence artificielle elle-meme ou les trois createurs qui l'ont programmee.

Des reseaux antagonistes generatifs ont parfois ete utilises pour creer de fausses images realistes, comme avec le generateur de visages StyleGAN introduit en 2018, ou avec  Terre Seconde  de Gregory Chatonsky qui imagine en 2019 une version alternative de la planete Terre.
Des 2022 apparaissent des modeles d'intelligence artificielle qui sont capables de creer des images realistes a partir de descriptions textuelles, comme Midjourney, Stable Diffussion et DALL-E,. En mars 2023, des fausses photos d'actualite sont ainsi generees et diffusees sur Internet, mettant en scene des personnalites dans des situations extravagantes (le president Macron ramassant des poubelles, Donald Trump arrete par des policiers, le pape Francois habille en doudoune blanche). Elles deviennent rapidement virales, augmentant les craintes de manipulation de l'opinion. Cela pose aussi des questions de droits d'auteur.

De plus en plus de romans ont ete coecrits avec une IA generative, tels que Internes en 2022 ou  ( La Tour de la compassion de Tokyo ), qui a recu le prix Akutagawa en 2024.
En fevrier 2024, le modele Sora de OpenAI s'est montre capable de generer des videos relativement realistes.
Des modeles d'IA capables de generer un morceau de musique a partie d'une description du style souhaite ont egalement fait leur apparition, comme Suno AI en 2023 et Udio en 2024.

Autres domaines
La domesticite, avec des robots employe de maison, ou pour certaines taches precises comme en domotique.
En programmation informatique, notamment pour la maintenance previsionnelle, l'autocompletion ou l'aide au developpement.
En journalisme : des IA (appelees improprement  robots journalistes ) pourraient a terme aider les journalistes en les debarrassant de certaines taches, notamment la veille, le batonnage de depeches ou la verification des fake news.
La Coree du Sud propose la toute premiere animatrice tele virtuelle en novembre 2020 lors d'un JT.
En design : la conception assistee par ordinateur fait depuis longtemps appel a des algorithmes d'optimisation. En 2019, le createur Philippe Starck lance ainsi une chaise developpee en collaboration avec la societe Autodesk, la  A.I.chair .

Debats et enjeux
Les succes en IA encouragent les speculations. Dans les milieux technophiles, on verse en general dans l'enthousiasme, le mouvement transhumaniste en est la meilleure expression. Mais certains s'inquietent et s'interrogent, parfois alarmistes, y compris dans la sphere de la haute technologie. Ainsi, des figures reputees telles que Bill Gates  ancien PDG de Microsoft et  figure emblematique de la revolution informatique de la fin du XXe siecle   pensent qu'il faut rester tres prudent quant aux developpements futurs de ces technologies, qui pourraient devenir liberticides ou dangereuses.
Le developpement de l'intelligence artificielle suscite un grand nombre de questions, notamment en ce qui concerne la possibilite pour les IA ou algorithmes d'acceder un jour a la conscience, d'eprouver des emotions ou de finalement se substituer aux humains. Certaines reactions sont ouvertement optimistes, d'autres sont au contraire pessimistes. En 2016, l'INRIA publie un premier Livre blanc consacre a l'IA.
Le philosophe Daniel Andler considere en 2023 que le reve d'une intelligence artificielle qui rejoindrait celle de l'homme est une chimere, pour des causes conceptuelles et non techniques. L'intelligence humaine va selon lui plus loin que la simple resolution de problemes : toutes ses autres taches, reposant sur des affects, de la spontaneite et une forme de contingence, ne seront jamais accessibles a une intelligence non humaine.

Singularite
Une description d'un possible avenir de l'intelligence artificielle a ete faite par le statisticien anglais Irving John Good :
 Supposons qu'existe une machine surpassant en intelligence tout ce dont est capable un homme, aussi brillant soit-il. La conception de telles machines faisant partie des activites intellectuelles, cette machine pourrait a son tour creer des machines meilleures qu'elle-meme ; cela aurait sans nul doute pour effet une reaction en chaine de developpement de l'intelligence, pendant que l'intelligence humaine resterait presque sur place. Il en resulte que la machine ultra intelligente sera la derniere invention que l'homme aura besoin de faire, a condition que ladite machine soit assez docile pour constamment lui obeir. 

 Irving John Good
Cette hypothetique courte periode de progres drastique dont il est difficile de predire les consequences a ete nommee  singularite . Elle a ete etudiee par Vernor Vinge dans les annees 90 et par Ray Kurzweill dans les annees 2000. Ce concept est central pour de nombreux transhumanistes, qui s'interrogent sur les dangers ou les espoirs d'un tel scenario, certains allant jusqu'a envisager l'emergence d'un  dieu  numerique appele a prendre le controle du destin de l'humanite, ou a fusionner avec elle. En 2014, Nick Bostrom a popularise le concept de superintelligence artificielle.

Risques existentiels
Le developpement de l'intelligence artificielle genere de l'enthousiasme, mais aussi de vives inquietudes. Certains auteurs de science-fiction, tels Isaac Asimov, William Gibson ou Arthur C. Clarke, sur le modele du recit de L'Apprenti sorcier, decrivent le risque d'une perte de controle des humains sur le processus technique. Dans les annees 2010, differents intellectuels ont egalement pris position, notamment l'astrophysicien Stephen Hawking, selon qui l'intelligence artificielle risque reellement de surpasser un jour l'intelligence humaine et de finir par dominer l'humanite, voire de s'y substituer,. Il pose en novembre 2017 au salon technologique Web Summit de Lisbonne la question suivante  Serons-nous aides par l'intelligence artificielle ou mis de cote, ou encore detruits par elle ? .
Dans le milieu de la haute technologie, certains expriment publiquement des craintes similaires. C'est ainsi le cas, en 2015, de Bill Gates, Elon Musk et Bill Joy. Selon le specialiste americain de l'informatique Moshe Vardi en 2016, l'intelligence artificielle pourrait mettre 50 % de l'humanite au chomage.  Nous approchons d'une epoque ou les machines pourront surpasser les hommes dans presque toutes les taches .
Hilary Mason, directrice de la recherche a Cloudera, a critique en 2018 le sensationnalisme entourant l'intelligence artificielle et prone une vision pragmatique et operationnelle de cette technologie.
Ajouter un mecanisme d'arret pourrait ne pas suffire face a une IA suffisamment avancee, qui pourrait s'averer en mesure de cacher des intentions dangereuses, de manipuler ses detenteurs, de desactiver le mecanisme d'arret ou encore de se dupliquer. Selon Nick Bostrom en 2015, la seule solution viable a long terme consiste a trouver comment aligner les intelligences artificielles avec des valeurs humaines et morales :

 nous ne devrions pas etre confiants dans notre capacite a garder indefiniment un genie superintelligent enferme dans une bouteille. Je crois que la reponse ici est de trouver comment creer une IA superintelligente de sorte que si  ou plutot quand  elle s'echappe, elle reste sans danger, parce qu'elle est fondamentalement de notre cote, elle partage nos valeurs. 

 Nick Bostrom
Roman V. Yampolskiy, professeur de science informatique a l'Universite de Louisville, evoque pourquoi et comment une IA obtient un resultat, pour s'assurer qu'il corresponde bien a l'attendu, sans biais :  si nous nous habituons a accepter les reponses de l'IA comme des paroles d'oracles ne necessitant pas d'explication, alors nous serons incapables de verifier si ces resultats ne sont pas biaises ou manipules .
En mai 2023, une declaration du Center for AI Safety ( Centre pour la surete de l'IA ) affirme que reduire le risque d'extinction de l'humanite lie a l'IA devrait etre une priorite mondiale, au meme titre que pour d'autres risques civilisationnels tels les pandemies ou les guerres nucleaires. Elle est signee par des dirigeants de laboratoires d'IA comme OpenAI, Google DeepMind ou Anthropic, ainsi que par des chercheurs en intelligence artificielle,.

Critique de la technique et de la technologie
Comme l'explique l'historien Francois Jarrige, la critique de l'intelligence artificielle trouve son origine dans celle - plus ancienne et plus generale - des techniques et de la technologie, dont Lewis Mumford (aux Etats-Unis), Jacques Ellul (en France) et Gunther Anders (en Allemagne) sont au XXe siecle les principaux instigateurs, et qui inspire aujourd'hui differents cercles militants (en France, par exemple : Pieces et Main d'uvre et Technologos).
Dans un rapport en date de fevrier 2018 intitule The Malicious Use of Artificial Intelligence 26 experts specialistes en intelligence artificielle mettent en garde contre les dangers d'un usage criminel de l'IA : augmentation de la cybercriminalite, conduire a des utilisations de drones a des fins terroristes, manipulation de masse, etc..

Impact environnemental
Un autre probleme est l'enorme quantite de ressources rares, de serveurs et d'energie consommee par l'informatique sous-jacente a l'IA. Google admet en 2024 qu'il lui sera tres difficile de tenir ses engagements de neutralite carbone, car depuis 2019 ses emissions de gaz a effet de serre ont augmente de 48 % du fait du developpement de l'IA.
Afin de reduire leur empreinte carbone, certains fournisseurs d'IA (Microsoft, Amazon et Oracle) se tournent vers les marches volontaires de la compensation carbone, et plus largement de solutions de decarbonation, comme celles de capture du CO2. Ils s'orientent egalement vers les centrales nucleaires pour couvrir leur besoin en electricite. Microsoft a notamment signe en 2024 un contrat avec Constellation Energy pour l'achat de 837 MWe de capacite electrique fournie par la centrale nucleaire de Three Mile Island, pour une duree de vingt ans a partir de 2028.

Open source
Divers projets open source d'IA ont ete menes par Hugging Face, EleutherAI, Google, ou Meta.
En mars 2023, comme alternative aux geants du Web et du cloud computing, qui ont le plus de pouvoir et d'influence, Mozilla annonce vouloir investir 30 millions de dollars dans un projet baptise Mozilla.ai, qui est a la fois une startup et une communaute, independante des geants de la tech et de la recherche universitaire. Le projet vise a creer, dans le respect des valeurs de son manifeste (notamment transparence et responsabilite), un systeme d'IA  open source, digne de confiance et independant .
De nombreux grands modeles de langage comme Mistral, Llama 3, Vicuna et Falcon sont rendus open weight, ce qui signifie que l'architecture et les parametres entraines du modele d'IA sont rendus publics (open source impliquerait notamment de partager les donnees d'entrainement, ce qui souvent n'est pas le cas). Ces modeles peuvent etre librement ajustes, ce qui permet notamment aux entreprises de les specialiser pour leurs propres donnees et pour leur cas d'usage. Ces modeles d'IA facilitent l'innovation et la recherche, mais peuvent facilement etre detournes. Ils peuvent etre reentraines de sorte a rendre inefficaces les mesures de securite, telles que le refus de repondre a une requete dangereuse. Certains chercheurs estiment ainsi que si des modeles developpent un jour des capacites dangereuses, comme le fait de faciliter drastiquement les cyberattaques ou le bioterrorisme, ils ne devraient pas etre rendus open weight, d'autant plus qu'une fois diffuse sur internet, un modele ne peut en general plus etre supprime partout,.

IA et emploi
Historiquement, l'innovation technologique a generalement ete accompagnee d'une croissance de la productivite et de la creation de nouveaux emplois pour compenser les pertes. Cependant, de nouvelles inquietudes ont emerge avec l'essor de l'IA generative, telle que ChatGPT, capable de manipuler du texte, des images ou du code informatique.
Certains economistes sont sceptiques a l'idee d'un chomage de masse, citant des precedents historiques ou le marche du travail s'est adapte a des bouleversements technologiques,. D'autres estiment que l'IA generative represente un changement plus profond, qui ne consiste pas seulement a automatiser des taches repetitives. L'IA peut etre appliquee a tous les secteurs, et le nombre de taches ou l'humain reste plus competent que l'IA est amene a diminuer,.
Une etude de Goldman Sachs a estime en 2023 que les deux tiers des travailleurs europeens sont exposes a divers degres d'automatisation, et qu'un quart des emplois pourraient etre remplaces par l'IA. L'etude predit notamment que les professions administratives et legales seront particulierement touchees, la ou les metiers manuels en exterieur seront peu affectes.
Une solution envisagee dans le scenario d'un chomage de masse est celle d'une forme de redistribution des richesses avec un revenu universel. Les financements pourraient dans ce cas venir d'une taxe sur les richesses produites par les machines.

Defaut de representativite
L'IA s'appuie sur l'analyse de donnees qui ne peuvent generalement pas representer fidelement la realite, soit parce ces donnees ne proviennent que de sources numeriques existantes (le plus souvent sur Internet) alors que quantites d'informations pertinentes pour le domaine considere n'y figurent pas, soit parce que certaines categories de donnees pourtant pertinentes n'ont pas ete prises en compte, ou que des donnees non pertinentes l'ont ete. Il en resulte alors une inadequation entre les donnees utilisees pour lentrainement des algorithmes et les donnees cibles sur lesquelles lalgorithme devra operer, et par consequent des erreurs de diagnostic qui peuvent, dans certains cas, induire des decisions inappropriees ou injustes,,.

Risques politiques et sociaux
Les reseaux sociaux et les bots ont favorise la propagation de nombreuses fausses croyances et des derives dans les debats democratiques, lesquelles ont entraine une certaine defiance vis-a-vis de la science, des elites intellectuelles et des medias d'information traditionnels[ref. incomplete]. En consequence, la progression et l'adoption rapides des techniques sous-jacentes de l'IA inspirent de multiples craintes quant aux impacts que celle-ci pourrait avoir sur les comportements individuels et collectifs. Ces conditions ouvrent la possibilite pour des operateurs majeurs de la societe de fausser le reel pour influencer ou manipuler les citoyens. Les acteurs economiques emploient l'IA pour influencer les consommateurs et pour optimiser le travail de leurs employes au point de les transformer en robots[source secondaire souhaitee]. L'eventualite que l'IA intervienne dans les debats d'idees ou dans la conduite des affaires individuelles ou collectives mene a redouter qu'elle n'altere ou n'affaiblisse les institutions politiques[ref. incomplete] et les pouvoirs, voire les capacites des humains[source secondaire souhaitee].
Des 2010, Nicholas Carr alertait sur l'usage intensif des outils numeriques, qui modifie notre maniere de penser et de traiter l'information, ce qui peut avoir des consequences a long terme sur notre cognition, notamment affaiblir notre memoire et notre capacite a comprendre les informations de maniere approfondie et affecter la creativite, l'empathie et le debat intellectuel.
Les principales menaces couramment envisagees, consecutives a des biais ou au detournement des algorithmes d'IA sont, :

la desinformation et la manipulation du public pour des raisons crapuleuses, religieuses ou ideologiques ;
les fausses videos et hypertrucages representant des personnalites faisant ou disant des choses qu'ils n'ont pas faites ou dites ;
la corruption de donnees par vandalisme ou pour destabiliser ou soutirer de fortes sommes d'argent (par rancongiciel) en empechant l'acces a des donnees ou des services ;
l'escroquerie par usurpation d'identite ou pour soutirer de l'argent contre des biens ou des services fictifs ;
le chantage a grande echelle, par des menaces d'agression ou de revelations sur la vie privee ;
la perte de controle ou le piratage d'infrastructures publiques (eau, energie, signalisation routiere, Internet, services en ligne) a des fins de destabilisation ou de chantage ;
la perte de controle de robots, de vehicules autonomes ou de drones militaires, ou leur vol ou leur detournement a des fins agressives ou de chantage ;
la manipulation de marches financiers ;
la surveillance de masse.
De plus, l'IA produit parfois des resultats contre-intuitifs, bien que fiables, ou propager de fausse croyances, qui contribuent, parmi d'autres facteurs, a eroder la confiance d'une partie de la population dans le discours rationnel, les theories scientifiques, le systeme mediatique, les institutions et les elites en general, et a la remise en cause de leurs legitimites et du processus democratique[ref. incomplete].
Selon Yuval Noah Harari, jusqu'ici, du fait de defauts d'alignement et faute de mecanismes suffisants d'autocorrection, les objectifs qui sont assignes aux algorithmes des reseaux sociaux ont deja induit ou influence phenomenes de societe indesirables, desinformation, hypertrucages, propos outranciers ou haineux, comme dans le cas du genocide des Rohingya au Myanmar, en outrepassant les regles ethiques qui sont implicites pour des humains. De plus, la capacite de l'IA a fonder ses analyses sur des volumes considerables de donnees et de tres nombreux criteres donne l'illusion de son infaillibilite, comparativement aux methodes d'analyse par des individus ou des organisations humaines, fondes sur des corpus d'information beaucoup plus reduits et un nombre de criteres limite dont certains tres subjectifs. Certains algorithmes d'IA ont meme la faculte d'inspirer confiance aux humains en misant sur leur subjectivite ou leur emotivite, voire de les tromper  deliberement  pour parvenir a leurs fins,. L'exploitation de telles possibilites pourrait permettre de constituer un ou plusieurs nouveaux systemes de croyances et de regles morales, politiques et sociales, a l'instar des religions ou des regimes politiques, instituant comme verite une certaine interpretation du reel et etablissant une nouvelle forme d'ordre social. L'IA pourrait ainsi conduire a une certaine anarchie ou permettre l'instauration de regimes totalitaires dans les pays democratiques (a contrario, des IA pourraient amplifier ou faire naitre des idees subversives au sein des regimes autoritaires). Pour preserver les democraties, il conviendrait donc que soient etablies des regulations faisant intervenir des humains pour contenir les possibles derives de l'IA[ref. incomplete].
L'emploi de l'IA pour noter les entreprises et citoyens, sur le modele du credit social, est deja a l'uvre en Chine. Ce procede fait craindre une surveillance constante des personnes et des organisations, pouvant entrainer une forme d'asservissement des individus, ou des sanctions et recompenses excessives[ref. incomplete].
Eric Sadin recuse le terme d' intelligence . Selon lui, l'IA porte en elle un modele de societe utilitariste et rationaliste inspire de maniere extremement lacunaire par le fonctionnement du cerveau humain et visant a uniformiser les comportements en temps reel et a tous moments. Le liberalisme economique, saisissant le profit qu'il peut en tirer, investit massivement dans l'IA afin d'exploiter l'inclination naturelle des humains a la facilite et les capacites extraordinaires de l'IA a expertiser la complexite du reel et a orienter nos decisions. Cela nous conduit insidieusement a nous fier aux reponses formulees par des algorithmes au detriment de criteres d'analyse plus multisensoriels et de choix plus subjectifs, donc plus humains. Nous pourrions alors ceder progressivement a l'IA notre pouvoir d'analyse, de jugement et de decision et consentir a nous soumettre plus ou moins consciemment a une  intelligence  superieure, puis finalement renoncer meme a penser. Notre addiction aux  assistants personnels  et aux capteurs physiologiques ainsi que leur presence continuelle a nos cotes pourraient les amener progressivement a s'exprimer, decider voire imaginer a notre place et en notre nom, d'abord avec, puis ensuite sans notre consentement.
Selon Laurent Alexandre, l'IA contribuera a accroitre les inegalites en ecartant les individus les  moins aptes  de l'activite economique et sociale, et le revenu universel constituerait a ses yeux un moyen d'asseoir la domination des  elites  sur les populations defavorisees.

Reglementation
En 2019, l'OCDE et le G20 adoptent une serie de principes sur l'IA. Le Partenariat mondial sur l'intelligence artificielle est lance en juin 2020 pour promouvoir la conformite du developpement de l'IA aux droits de l'homme et aux valeurs democratiques. Il est heberge par l'OCDE a Montreal et a Paris. Une plateforme de communication, AI for Good ( l'IA pour le bien ), est creee pour faciliter les echanges et faire avancer les objectifs de developpement durable de l'ONU grace a l'IA.
En 2023, plus de 1 600 politiques publiques et strategies sur l'IA sont recensees dans le monde. Elles viennent en particulier de l'Union europeenne, la Chine, les Etats-Unis et le Royaume-Uni. Apres les avancees reglementaires de l'UE et de la Chine, la Maison-Blanche publie en octobre 2023 un decret sur l'IA  sure, securisee et digne de confiance . En novembre 2023 a lieu un premier sommet en securite de l'IA au Royaume-Uni.
En Europe, les services numeriques sont reglementes par le RGPD, le reglement sur les services numeriques et la legislation sur les marches numeriques. Pour l'intelligence artificielle en particulier, la legislation sur l'intelligence artificielle (Artificial Intelligence Act, ou AI Act en anglais) definit quatre niveaux de risques pour les applications d'IA et met en avant des exigences de transparence, de protection des donnees, de securite et d'ethique.
En 2017, les Emirats arabes unis sont le premier pays au monde a se doter d'un ministre dedie a l'intelligence artificielle : Omar Sultan Al Olama.

Appels a des regles ethiques pour l'IA
Dans la seconde moitie des annees 2010, des lanceurs d'alerte et des enquetes revelent que l'IA, encore emergente, a deja ete utilisee a des fins malveillantes pour faire basculer des processus electoraux. Le premier cas notable a ete la plate-forme RIPON, secretement creee par le Groupe SCL, a la demande de Steve Bannon et du milliardaire americain Robert Mercer. Cette plateforme, principalement au service de groupes politiques libertariens de droite, a ete un outil de desinformation, de production et de diffusion de fake news a grande echelle,. Ripon, impliquee dans le scandale Facebook-Cambridge Analytica/Aggregate IQ), joua un role important dans la manipulation dun grand nombre d'electeurs, notamment pour faire elire Donald Trump lors de l'election presidentielle americaine de 2016, pour faire advenir le Brexit, ainsi que pour orienter des dizaines d'elections dans le monde.
Face a ces derives, les geants du secteur de lIA ont reagi en creant le 28 septembre 2016 un  partenariat pour l'intelligence artificielle au benefice des citoyens et de la societe . L'annee suivante, Google DeepMind se dote d'une unite interne pour aborder les questions ethiques et la conference d'Asilomar rassemblant des personnalites influentes propose une charte pour reglementer les developpements en IA.
Le 18 juillet 2018, 2 400 chercheurs, ingenieurs et personnalites du secteur de l'intelligence artificielle signent une lettre ouverte, s'engageant a  ne jamais participer ou soutenir le developpement, la fabrication, le commerce ou l'usage d'armes letales autonomes . La lettre precise que  La decision de prendre une vie humaine ne devrait jamais etre deleguee a une machine . Parmi les signataires se trouvent Elon Musk, les dirigeants de Google DeepMind Stuart Russell, Yoshua Bengio, et Toby Walsh.
Fin 2020, l'UNESCO rejoint (en tant qu'observateur, comme l'OCDE) le conseil et le comite directeur du Partenariat mondial sur l'intelligence artificielle, avec la possibilite de participer activement aux travaux de ces organismes.
La publication en fevrier 2020 d'un Livre blanc sur l'intelligence artificielle, pose les bases du reglement sur l'intelligence artificielle de 2021 par la Commission europeenne, qui vise a encadrer les risques et les problemes ethiques de ces technologies. Ce projet classe les risques en quatre categories, dont la plus grave est qualifiee comme suit :

 Risque inacceptable : les systemes d'IA consideres comme une menace evidente pour la securite, les moyens de subsistance et les droits des personnes seront interdits. Il s'agit notamment des systemes ou applications d'IA qui manipulent le comportement humain pour priver les utilisateurs de leur libre arbitre (par exemple, des jouets utilisant une assistance vocale incitant des mineurs a avoir un comportement dangereux) et des systemes qui permettent la notation sociale par les Etats. 

En decembre 2022, le  premier forum mondial sur l'ethique de l'IA , reunion ministerielle internationale, est reuni a Prague, sous l'egide de l'Unesco.
La meme annee, lUnesco, estimant que  l'autoregulation de l'industrie n'est manifestement pas suffisante pour eviter ces prejudices ethiques , a publie un communique (adopte le 23 novembre 2021) demandant a tous les Etats de mettre en uvre sa recommandation sur l'ethique de l'intelligence artificielle afin de construire un cadre legislatif et ethique pour l'IA.
Lobjectif est de n'utiliser lIA que lorsque les atouts qu'elle peut offrir sont bien identifies, et quon peut eviter, limiter et reparer les risques qui lui sont associes (en particulier lors d'usages non-pacifiques, malveillants et/ou aggravant les inegalites et des clivages). Ici, l'ONU, invite a ne pas utiliser l'IA quand elle met en peril la protection des donnees (tous les individus doivent pouvoir effacer et acceder aux enregistrements de leurs donnees personnelles, et les organismes de reglementation du monde entier doivent faire respecter ces dispositions). Cette recommandation vient aussi interdire la notation sociale et la surveillance de masse, contraires aux droits de l'homme et aux libertes fondamentales, et rejette lidee daccorder une personnalite juridique a lIA  La Recommandation souligne que, lors de l'elaboration de cadres reglementaires, les Etats membres doivent tenir compte du fait que la responsabilite et l'obligation de rendre des comptes incombent toujours aux etres humains en dernier ressort et que les technologies de l'IA ne devraient pas etre dotees elles-memes d'une personnalite juridique .
Levaluation des IA prend en compte ses impacts ethiques sur les individus, sur la societe et sur l'environnement. Lobjectif etant a terme de creant une infrastructure juridique et technique ad hoc, ainsi quun responsable (independant) de l'ethique de l'IA pour surveiller lutilisation et la creation des IA qui devraient  privilegier les methodes d'IA economes en donnees, en energie et en ressources . Dun point de vue ecologique, les gouvernements sont invites, lors du cycle de vie du systeme d'IA a analyser son  empreinte carbone, sa consommation d'energie et l'impact environnemental de l'extraction des matieres premieres pour soutenir la fabrication des technologies d'IA , tout en cherchant a diminuer l'impact environnemental du numerique en investissant dans les technologies vertes. Ainsi,  si les systemes d'IA ont un impact negatif disproportionne sur l'environnement, la Recommandation preconise de ne pas les utiliser .
En 2023, lUNESCO reitere son appel a la mise en uvre rapide de sa Recommandation sur lethique de lintelligence artificielle, adoptee a l'unanimite par les 193 Etats-membres.  Cest le defi de notre temps , et il est  urgent que tous transposent ce cadre sous la forme de strategies et de reglementations nationales. Nous devons traduire les engagements en actes  a commente Audrey Azoulay (directrice generale de l'Unesco). L'ONU appelle ainsi les Etats qui ne l'ont pas deja fait a rejoindre les plus de 40 pays  de toutes les regions du monde  qui ont commence a creer de tels garde-fous, pour notamment creer un outil legislatif capable d'encadrer et de surveiller les IA, tout en veillant a la protection des donnees personnelles et sensibles, et en sensibilisant la population mondiale a un usage responsable de l'IA.
En 2023, lors de la 57e Journee mondiale de la paix, le pape Francois exprime ses preoccupations quant aux consequences potentielles de l'IA sur la paix mondiale et demande a la communaute internationale de definir un traite international contraignant pour reglementer son developpement et son utilisation. Il se montre particulierement preoccupe par  la possibilite de mener des operations militaires a travers des systemes de controle a distance , citant notamment les systemes darmes letales autonomes.

Droits des robots
En 2017, le Parlement europeen a demande a une commission d'etudier la possibilite qu'un robot dote d'une intelligence artificielle puisse etre considere comme une personne juridique,. Advenant un dommage cause a un tiers par une intelligence artificielle, celle-ci pourrait etre condamnee a reparer ce dommage. Il serait envisageable de conferer une personnalite electronique a tout robot prenant des decisions autonomes ou interagissant de maniere independante avec des tiers, au meme titre qu'une personne morale et physique.

Gouvernance democratique
En 2023, Mark Coeckelbergh et Henrik Skaug Saetra, respectivement philosophe renomme de l'ethique des technologies et expert en sciences politiques, se penchent sur la question de l'intelligence artificielle (IA) et son potentiel role dans la lutte contre le changement climatique. Ils plaident pour une integration des IA dans les politiques democratiques, soulignant quelles peuvent faciliter la deliberation et la prise de decisions. Toutefois, ils avertissent egalement que l'IA pourrait devenir un outil si puissant qu'il pourrait entierement remplacer le gouvernement, entrainant des problemes sociaux majeurs.
Pour illustrer leur propos, Coeckelbergh et Saetra presentent deux cas extremes : une democratie sans remplacement des humains (AI-augmented democracy) et une technocratie dirigee par l'IA (AI-driven technocracy). Ces deux cas extremes sont choisis pour demontrer les implications opposees de l'integration de l'IA dans la gouvernance.
Dans une democratie sans remplacement des humains, lIA est presentee comme un simple outil visant a faciliter la prise de decision. Par exemple, elle peut etre utilisee pour la traduction, la verification des faits, ou la prise de notes. Ici, l'IA soutient le processus democratique sans en prendre le controle.
En revanche, dans une democratie avec remplacement, lIA prend toutes les decisions, sans aucune intervention humaine. Cette approche, selon Saetra, pose cinq problemes majeurs :

les citoyens ont besoin d'une pleine participation politique pour etre satisfaits ;
les citoyens ne considerent pas comme legitime un gouvernement auquel ils ne participent pas ;
les ordinateurs ne devraient pas prendre de decisions affectant la vie et le bien-etre des personnes ;
l'IA n'est pas transparente et ne peut donc pas etre entierement controlee par l'homme ;
l'obligation de rendre compte des consequences des decisions politiques doit etre claire, ce qui devient de moins en moins le cas lorsque l'IA prend des decisions.
Ces points soulignent les consequences sociales et ethiques de la prise de decision par lIA en ce qui concerne les humains. Ainsi, Coeckelbergh et Saetra concluent qu'une democratie sans remplacement des humains est plus adaptee, lIA y etant presente uniquement comme soutien et non comme entite decisionnelle.
Les deux auteurs estiment cependant quaucune des deux propositions nest actuellement realisable : les relations entre les humains et la technologie ne sont pas suffisamment evoluees pour permettre une utilisation ethique de lIA. Ainsi, les decisions ne peuvent pas etre prises uniquement par lIA, car les erreurs sont encore trop frequentes et les normes sociales et ethiques peu respectees.

Demandes de moratoire
Debut 2023, l'apparition de ChatGPT suscite une grande curiosite, de l'enthousiasme, mais aussi des craintes serieuses :  Devons-nous laisser les machines inonder nos canaux d'information de propagande et de mensonges? () Devons-nous risquer de perdre le controle de notre civilisation? Ces decisions ne doivent pas etre deleguees a des leaders technologiques non elus  affirment Elon Musk, Steve Wozniak (cofondateur d'Apple) et des centaines d'experts. Le 29 mars 2023, ceux-ci, invoquant des  risques majeurs pour l'humanite , signent une petition qui appelle le monde a un moratoire d'au moins six mois sur ces recherches, jusqu'a la mise en place de systemes de securite, incluant : la creation d'autorites reglementaires dediees, des moyens pour efficacement surveiller des IA et des systemes les utilisant, la mise a disposition de techniques permettant de mieux differencier le reel de l'artificiel, et la creation d'institutions pouvant limiter les  perturbations economiques et politiques dramatiques (en particulier pour la democratie) que l'IA provoquera .

Philosophie
Courants de pensee
La cybernetique naissante des annees 1940 revendiquait tres clairement son caractere pluridisciplinaire et se nourrissait des contributions les plus diverses : neurophysiologie, psychologie, logique, sciences sociales, etc. Elle envisagea deux approches des systemes, approches reprises par les sciences cognitives et de ce fait l'intelligence artificielle[ref. souhaitee] : une approche par la decomposition (du haut vers le bas, comme avec les systemes experts) et une approche contraire par construction progressive du bas vers le haut, comme avec l'apprentissage automatique.
Ces deux approches se revelent plutot complementaires que contradictoires : on est a l'aise pour decomposer rapidement ce que l'on connait bien, et une approche pragmatique a partir des seuls elements que l'on connait afin de se familiariser avec les concepts emergents est plus utile pour les domaines inconnus. Elles sont respectivement a la base des hypotheses de travail que constituent le cognitivisme et le connexionnisme, qui tentent aujourd'hui (2005)[Passage a actualiser] d'operer progressivement leur fusion.
Le guide pratique de Linux sur l'intelligence artificielle v3.0, revise le 15 decembre 2012, adopte pour la commodite du lecteur la taxinomie suivante :

systemes symboliques ;
connexionnisme ;
calcul evolutif (algorithmes genetiques, par exemple) ;
alife (vie artificielle) et complexite ;
agents et robotique.

Cognitivisme
Le cognitivisme considere que le vivant, tel un ordinateur (bien que par des procedes tres differents), manipule essentiellement des symboles elementaires. Dans son livre La societe de l'esprit, Marvin Minsky, s'appuyant sur des observations du psychologue Jean Piaget, envisage le processus cognitif comme une competition d'agents fournissant des reponses partielles et dont les avis sont arbitres par d'autres agents. Il cite les exemples suivants de Piaget :

l'enfant croit d'abord que plus le niveau d'eau est eleve dans un verre, plus il y a d'eau dans ce verre. Apres avoir joue avec des transvasements successifs, il integre le fait que la notion de hauteur du liquide dans le verre entre en competition avec celle du diametre du verre, et arbitre de son mieux entre les deux ;
il vit ensuite une experience analogue en manipulant de la pate a modeler : la reduction de plusieurs objets temporairement representes a une meme boule de pate l'incite a degager un concept de conservation de la quantite de matiere.
Au bout du compte, ces jeux d'enfants se revelent essentiels a la formation de l'esprit, qui degagent quelques regles pour arbitrer les differents elements d'appreciation qu'il rencontre, par essais et erreurs.

Connexionnisme
Le connexionnisme, se referant aux processus auto-organisationnels, envisage la cognition comme le resultat d'une interaction globale des parties elementaires d'un systeme. On ne peut nier que le chien dispose d'une sorte de connaissance des equations differentielles du mouvement, puisqu'il arrive a attraper un baton au vol, ni qu'un chat ait aussi une sorte de connaissance de la loi de chute des corps, puisqu'il se comporte comme s'il savait a partir de quelle hauteur il ne doit plus essayer de sauter directement pour se diriger vers le sol. Cette faculte, qui evoque l'intuition des philosophes, se caracteriserait par la prise en compte et la consolidation d'elements perceptifs dont aucun pris isolement n'atteint le seuil de la conscience, ou en tout cas n'y declenche d'interpretation particuliere.

Synthese
Trois concepts reviennent de facon recurrente dans la plupart des travaux :

la redondance (le systeme est peu sensible a des pannes ponctuelles) ;
la reentrance (les composants s'informent en permanence entre eux ; cette notion differe de la reentrance en programmation) ;
la selection (au fil du temps, les comportements efficaces sont degages et renforces).

Intelligence artificielle forte
Le concept d'intelligence artificielle forte fait reference a une machine capable non seulement de produire un comportement intelligent, notamment de modeliser des idees abstraites, mais aussi d'eprouver une impression d'une reelle conscience, de  vrais sentiments  (notion dont la definition n'est pas universelle), et  une comprehension de ses propres raisonnements .
Contrairement a l'intelligence artificielle generale, l'intelligence artificielle forte fait donc le plus souvent intervenir des notions philosophiques de conscience qui font que les capacites de l'intelligence artificielle ne suffisent pas a dire si elle est  forte . Cela dit, aucune definition de la conscience pour une IA ne fait consensus. Les termes  intelligence artificielle forte  et  intelligence artificielle generale  sont parfois en pratique utilises de maniere interchangeable.
En partant du principe, etaye par les neurosciences, que la conscience a un support biologique et donc materiel, les scientifiques ne voient generalement pas d'obstacle theorique a la creation d'une intelligence consciente sur un support materiel autre que biologique. Selon les tenants de l'IA forte, si a l'heure actuelle il n'y a pas d'ordinateurs ou d'algorithmes aussi intelligents que l'etre humain, ce n'est pas un probleme d'outil mais de conception. Il n'y aurait aucune limite fonctionnelle (un ordinateur est une machine de Turing universelle avec pour seules limites celles de la calculabilite), seulement des limites liees a l'aptitude humaine a concevoir les logiciels appropries (programme, base de donnees).

Diversite des opinions
Les principales opinions soutenues pour repondre a la question d'une intelligence artificielle forte (c'est-a-dire douee d'une sorte de conscience) sont les suivantes :

impossible : la conscience serait le propre des organismes vivants (superieurs), et elle serait liee a la nature des systemes biologiques. Cette position est defendue par certains philosophes et sociologues comme Harry Collins, pour qui l'intelligence requiert une immersion dans la societe humaine, et donc un corps humain, et peut rappeler le courant du vitalisme ;
impossible avec des machines manipulant des symboles comme les ordinateurs actuels, mais possible avec des systemes dont l'organisation materielle serait fondee sur des processus quantiques. Des algorithmes quantiques sont theoriquement capables de mener a bien des calculs hors de l'atteinte pratique des calculateurs conventionnels (complexite en 
  
    
      
        
          N
          
            3
          
        
      
    
    {\displaystyle N^{3}}
  
 au lieu de 
  
    
      
        
          2
          
            N
          
        
      
    
    {\displaystyle 2^{N}}
  
, par exemple, sous reserve d'existence du calculateur approprie). Au-dela de la rapidite, le scientifique Roger Penrose defend dans la theorie de la reduction objective orchestree l'idee controversee que la conscience necessiterait un fonctionnement non compatible avec les lois de la physique classique, et accessible uniquement a des systemes quantiques, ;
impossible car la pensee n'est pas un phenomene calculable par des processus discrets et finis. Cette theorie est notamment avancee par le philosophe John Searle et son experience de la chambre chinoise. Une conscience est donc necessaire pour acceder a l'intelligence, mais un systeme informatique ne serait capable que d'en simuler une, sans pour autant la posseder, renvoyant au concept philosophique du zombie ;
possible avec des ordinateurs manipulant des symboles. La notion de symbole est toutefois a prendre au sens large. Cette option inclut les travaux sur le raisonnement ou l'apprentissage symbolique base sur la logique des predicats, mais aussi les techniques connexionnistes telles que les reseaux de neurones, qui, a la base, sont definies par des symboles. Cette position est portee par des mouvements comme ceux du computationnalisme et est portee par des philosophes comme Hubert Dreyfus, pour qui le cerveau suit les lois de la physique et de la biologie, impliquant que l'esprit est donc un processus simulable. Cette derniere opinion constitue la position la plus engagee en faveur de l'intelligence artificielle forte.
Des auteurs comme Douglas Hofstadter (mais deja avant lui Arthur C. Clarke ou Alan Turing ; voir le test de Turing) expriment par ailleurs un doute sur la possibilite de faire la difference entre une intelligence artificielle qui eprouverait reellement une conscience, et une autre qui simulerait exactement ce comportement (voir Zombie (philosophie)). Apres tout, nous ne pouvons meme pas etre certains que d'autres consciences que la notre, y compris chez des humains, eprouvent reellement quoi que ce soit, si ce n'est par une petition de principe qui specule que chaque humain se retrouve a l'identique chez tous les autres. On retrouve la le probleme connu du solipsisme en philosophie.
Meme si une intelligence artificielle forte n'etait guere possible, une IA peut etre de plus en plus percue comme forte par une majorite d'individus parallelement a l'arrivee des IA generatives, dont les LLM (de l'anglais large language model) comme ChatGPT ou Google Bard, et les outils de generation d'images comme Midjourney, DALL-E ou Stable Diffusion. En effet, le champ d'applications de ces outils est beaucoup plus large qu'auparavant : creation, synthese, traduction de textes, composition d'images, de videos a partir de prompts, textes descriptifs. Il devient ainsi de plus en plus difficile pour un etre humain de distinguer des creations humaines de celles provenant d'une IA generative.
Emily Bender estime que les grands modeles de langage comme ChatGPT ne font que regurgiter plus ou moins aleatoirement des morceaux de texte venant des corpus ayant servi a leur entrainement, sans en comprendre le sens. Elle les appelle ainsi des  perroquets stochastiques . De meme, Jean-Gabriel Ganascia considere que le contenu qu'ils produisent n'est pas original et que leur utilisation dans la redaction d'articles de recherche constitue une forme de plagiat. Ilya Sutskever considere au contraire que ces modeles, a force d'etre entraines a predire le mot suivant, acquierent une forme de  modele du monde  et une representation  compressee, abstraite et utilisable  des concepts.

Intelligence artificielle faible
La notion d'intelligence artificielle faible constitue une approche pragmatique d'ingenieur : chercher a construire des systemes de plus en plus autonomes (pour reduire le cout de leur supervision), des algorithmes capables de resoudre des problemes d'une certaine classe, etc. Mais, cette fois, la machine simule l'intelligence, elle semble agir comme si elle etait intelligente.
Les tenants de l'IA forte admettent que s'il y a bien dans ce cas simple simulation de comportements intelligents, il est aise de le decouvrir et qu'on ne peut donc generaliser. En effet, si on ne peut differencier experimentalement deux comportements intelligents, celui d'une machine et celui d'un humain, comment peut-on pretendre que les deux choses ont des proprietes differentes ? Le terme meme de  simulation de l'intelligence  est conteste et devrait, toujours selon eux, etre remplace par  reproduction de l'intelligence .
Si le terme intelligence artificielle peut designer un systeme capable de resoudre plusieurs problemes de facon relativement autonome tout en ne faisant que simuler le principe d'intelligence, il peut aussi designer des systemes capables de resoudre uniquement un type de probleme pour un jeu de donnees predefini. On peut donner pour exemple un systeme entraine a reconnaitre des chiffres ecrits a la main, comme ceux utilises par La Poste, qui malgre sa grande performance sur sa tache, serait incapable de fonctionner sur un probleme sortant de ce pour quoi il a ete concu. Ces intelligences artificielles, aussi nommees  intelligences artificielles etroites  (terme issu de l'anglais narrow AI), sont concus pour effectuer une tache precise, contrairement a une intelligence artificielle generale.

Question de l'intelligence
La definition du terme  intelligence artificielle  pose une question fondamentale : Qu'est-ce que l'intelligence ?
L'intelligence peut se definir de maniere generale comme un ensemble de capacites cognitives permettant de resoudre des problemes ou de s'adapter a un environnement.
Le chercheur en IA Yann Le Cun avance que le noyau de l'intelligence est la faculte de predire. Les bases de la programmation des premiers systemes experts supposent de  maitriser parfaitement un probleme et d'avoir une vue precise de toutes les solutions , afin d'en programmer precisement le comportement. Mais les systemes d'IA modernes a base d'apprentissage automatique sont entraines a predire la reponse attendue, ou a generer une solution correcte. Leurs capacites emergent ainsi progressivement, par essai-erreur, sans que le programmeur n'ait besoin de fournir une solution algorithmique, ou meme de savoir comment resoudre le probleme. Dans tous les cas, l'efficacite de l'intelligence artificielle depend de sa capacite a repondre aux objectifs donnes par les programmeurs et a tendre vers l'autonomie decisionnelle, ce qui presuppose, entre autres, une capacite de prediction.
Le philosophe John Searle considere quant a lui que la faculte de comprendre est plus importante dans la definition de l'intelligence. Il essaie de demontrer la faiblesse des systemes d'intelligence artificielle et les limites du test de Turing, par son experience de la chambre chinoise, concluant :  on ne devrait pas dire d'une IA qu'elle comprend les informations qu'elle traite lorsqu'elle manipule des regles de syntaxe sans maitriser la semantique, c'est-a-dire sans reconnaitre le sens des mots. La question de savoir si on peut parler d'une veritable intelligence reste donc ouverte . L'apprentissage automatique fonctionne cependant differemment de l'IA symbolique, qui etait populaire a l'epoque ou Searle a concu l'experience de pensee de la chambre chinoise en 1980.

Dans la fiction
Une machine ayant une conscience et capable d'eprouver des sentiments  ou de faire comme si c'etait le cas  est un grand theme classique de la science-fiction, notamment des romans d'Isaac Asimov sur les robots.
Ce sujet a toutefois ete exploite tres tot, comme dans le recit des aventures de Pinocchio, publie en 1881, ou une marionnette capable d'eprouver de l'amour pour son createur cherche a devenir un vrai petit garcon, ou dans L'Homme le plus doue du monde, une nouvelle de l'Americain Edward Page Mitchell ou le cerveau d'un simple d'esprit est remplace par un ordinateur inspire des recherches de Charles Babbage. Le roman Le Miroir flexible de Regis Messac propose quant a lui le principe d'une intelligence artificielle faible, mais evolutive, avec des automates inspires de formes de vie simples, reagissant a certains stimuli tels que la lumiere. Cette trame a fortement inspire le film A.I. Intelligence artificielle realise par Steven Spielberg, sur la base d'idees de Stanley Kubrick, lui-meme inspire de Brian Aldiss. L'uvre de Dan Simmons, notamment le cycle d'Hyperion, evoque l'intelligence artificielle. Destination vide, de Frank Herbert, met en scene de maniere fascinante l'emergence d'une intelligence artificielle forte. Plus recemment, l'ecrivain francais Christian Leourier a place une intelligence artificielle au cur de son roman court Helstrid (2018), dans lequel cette IA laisse un etre humain mourir, contrevenant ainsi aux trois lois de la robotique instaurees par Isaac Asimov pres de quatre-vingts ans plus tot.
Les androides faisant preuve d'intelligence artificielle dans la fiction sont nombreux : le personnage de Data de la serie televisee Star Trek : The Next Generation est un etre cybernetique doue d'intelligence, avec des capacites importantes d'apprentissage. Il est officier superieur sur le vaisseau Enterprise et evolue aux cotes de ses coequipiers humains qui l'inspirent dans sa quete d'humanite. Son pendant cinematographique est Bishop dans les films Aliens (1986) et Alien 3 (1992). Dans le manga Ghost in the Shell, une androide s'eveille a la conscience. Dans la saga Terminator avec Arnold Schwarzenegger, le T-800 reprogramme, concu initialement pour tuer, semble dans la capacite d'eprouver des sentiments humains. Par ailleurs, les Terminators successifs sont envoyes dans le passe par Skynet, une intelligence artificielle qui a pris conscience d'elle-meme, et du danger que representent les humains envers elle-meme[ref. necessaire].
Dans le dernier episode de la saison 10 d'Inspecteur Derrick (diffuse en 1983), intitule Un homme en trop, le Professeur Romer (joue par Erich Hallhuber) veut arreter ses recherches sur l'intelligence artificielle, par peur du pouvoir sans conscience que cette nouvelle generation d'ordinateurs pourrait avoir sur les humains en finissant par les dominer et les tuer. Il abat son successeur pour l'empecher de continuer son travail.

Quelques IA celebres dans la science-fiction
Utilisation dans les jeux
Les jeux, notamment les jeux de strategie, ont marque l'histoire de l'intelligence artificielle, meme s'ils ne mesurent que des competences particulieres, telles que la capacite de la machine en matiere de calcul de probabilites, de prise de decision mais aussi d'apprentissage.
Hans Berliner (1929-2017), docteur en science informatique a l'universite Carnegie-Mellon et joueur d'echecs, fut l'un des pionniers de la programmation pour les ordinateurs de jeu. Ses travaux commencerent par un programme capable de battre un humain professionnel au backgammon, puis, a partir des annees 1960 et avec l'aide d'IBM, il fit des recherches pour creer un programme capable de rivaliser avec des grands maitres du jeu d'echecs. Ses travaux contribuerent quelques decennies plus tard a la realisation du supercalculateur Deep Blue.
Outre la capacite des jeux a permettre de mesurer les performances de l'intelligence artificielle, que ce soit au travers d'un score ou d'un affrontement face a un humain, les jeux offrent un environnement propice a l'experimentation pour les chercheurs, notamment dans le domaine de l'apprentissage par renforcement.

Othello
Dans le jeu Othello, sur un plateau de 8 cases sur 8, chaque joueur place tour a tour des pions de sa couleur (noir ou blanc). Le vainqueur est celui qui possede les pions de la couleur dominante.
L'une des premieres intelligences artificielles pour l'Othello est IAGO, developpee en 1976 par l'universite Caltech de Pasadena (Californie), qui bat sans difficultes le champion japonais Fumio Fujita.
Le premier tournoi d'Othello hommes contre machines est organise en 1980. Un an plus tard, un nouveau tournoi de programmes regroupent 20 systemes. C'est entre 1996 et 1997 que le nombre de programmes explose : Darwersi (1996-1999) par Olivier Arsac, Hannibal (1996) par Martin Piotte et Louis Geoffroy, Keyano (1997) par Mark Brockington, Logistello (1997) par Michael Buro, etc.

Echecs
En 1968, le maitre international anglais David Levy lanca un defi a des specialistes en intelligence artificielle, leur pariant qu'aucun programme informatique ne serait capable de le battre aux echecs dans les dix annees a venir. Il remporta son pari, n'etant finalement battu par Deep Thought qu'en 1989.
En 1988, l'ordinateur HiTech de Hans Berliner est le premier programme a battre un grand maitre du jeu d'echecs, Arnold Denker (74 ans) en match (3,5-1,5),.
En 1997, le supercalculateur concu par IBM, Deep Blue (surnomme Deeper Blue lors de ce match revanche), bat Garry Kasparov (3,52,5) et marque un tournant : pour la premiere fois, le meilleur joueur humain du jeu d'echecs est battu en match (et non lors d'une partie unique) par une machine.
En decembre 2017, une version generaliste d'AlphaGo Zero (le successeur du programme AlphaGo de DeepMind) nommee AlphaZero, est developpee pour jouer a n'importe quel jeu en connaissant seulement les regles, et en apprenant a jouer seul contre lui-meme. Ce programme est ensuite entraine pour le go, le shogi et les echecs. Apres 9 heures d'entrainement, AlphaZero bat le programme d'echecs Stockfish (leader dans son domaine), avec un score de 28 victoires, 72 nulles et aucune defaite. Il faut cependant noter que la puissance de calcul disponible pour AlphaZero (4 TPU v2 pour jouer, soit une puissance de calcul de 720 Teraflops) etait tres superieure a la puissance disponible de Stockfish pour ce match, ce dernier tournant sur un ordinateur equipe de seulement 64 curs Intel. AlphaZero a egalement battu (apres apprentissage) le programme de shgi Elmo (en),.

Go
En 2015, l'IA realise des progres significatifs dans la pratique du go, plus complexe a apprehender que les echecs (entre autres a cause du plus grand nombre de positions : 10170 au go, contre 1050 pour les echecs, et de parties plausibles : 10600 au go, contre 10120 pour les echecs).
En octobre 2015, AlphaGo, un logiciel d'IA concu par DeepMind, filiale de Google, bat pour la premiere fois Fan Hui, le triple champion europeen de go et ainsi releve ce qu'on considerait comme l'un des plus grands defis pour l'intelligence artificielle. Cette tendance se confirme en mars 2016 quand AlphaGo bat par trois fois consecutives le champion du monde de la discipline, Lee Sedol, dans un duel en cinq parties. Lee Sedol a declare au terme de la seconde partie qu'il n'avait trouve  aucune faiblesse  chez l'ordinateur et que sa defaite etait  sans equivoque .

Jeopardy!
En 2011, l'IA Watson concue par IBM bat ses adversaires humains au jeu televise americain Jeopardy!. Dans ce jeu de questions/reponses, la comprehension du langage est essentielle pour la machine ; pour ce faire, Watson a pu s'appuyer sur une importante base de donnees interne lui fournissant des elements de culture generale, et avait la capacite d'apprendre par lui-meme, notamment de ses erreurs. Il disposait neanmoins d'un avantage, la capacite d'appuyer instantanement (et donc avant ses adversaires humains) sur le buzzer pour donner une reponse.

Poker
En 2007, Polaris est le premier programme informatique a gagner un tournoi de poker significatif face a des joueurs professionnels humains,.
En 2017, lors du tournoi de poker  Brains Vs. Artificial Intelligence : Upping the Ante  ( Cerveau contre Intelligence Artificielle : on monte la mise ) organise dans un casino de Pennsylvanie, l'intelligence artificielle Libratus, developpee par des chercheurs de l'universite Carnegie-Mellon de Pittsburgh, est confrontee a des adversaires humains dans le cadre d'une partie marathon etalee sur 20 jours. Les joueurs humains opposes a Libratus, tous professionnels de poker, affrontent successivement la machine dans une partie en face a face (heads up (en)) selon les regles du  No Limit Texas hold'em  (no limit signifiant que les mises ne sont pas plafonnees), la version alors la plus courante du poker. Les parties sont retransmises en direct et durant huit heures par jour sur la plateforme Twitch.
Au terme de plus de 120 000 mains jouees, Libratus remporte tous ses duels face aux joueurs humains et accumule 1 766 250 dollars (virtuels). Le joueur humain ayant perdu le moins d'argent dans son duel face a la machine, Dong Kim, est tout de meme en deficit de plus de 85 000 dollars. Dans leurs commentaires du jeu de leur adversaire, les joueurs humains admettent que celui-ci etait a la fois deconcertant et terriblement efficace. En effet, Libratus  etudiait  chaque nuit, grace aux ressources d'un supercalculateur situe a Pittsburgh, ses mains jouees durant la journee ecoulee, utilisant les 15 millions d'heures-processeur de calculs du supercalculateur.
La victoire, nette et sans bavure, illustre les progres accomplis dans le traitement par l'IA des  informations imparfaites , ou la reflexion doit prendre en compte des donnees incompletes ou dissimulees. Les estimations du nombre de possibilites d'une partie de poker sont en effet d'environ 10160 dans la variante no limit en face a face.
Auparavant, en 2015, le joueur professionnel Doug Polk (en) avait remporte la premiere edition de cet evenement contre une autre IA, baptisee Claudico (en).

Bridge
En mars 2022, un logiciel de bridge de la start-up francaise Nukkai parvient a gagner un tournoi et a expliquer aux perdants leurs erreurs.

Notes et references
(en) Cet article est partiellement ou en totalite issu de larticle de Wikipedia en anglais intitule  Artificial intelligence  (voir la liste des auteurs).

Notes
References
Voir aussi
Articles connexes
Aspects juridiques

Legislation sur l'intelligence artificielle, aussi appelee AI Act
Digital Services Act, ou loi sur les services numeriques de l'Union europeenne
Notions generales

Notions techniques

Chercheurs en intelligence artificielle (espace anglophone)

Chercheurs en intelligence artificielle (espace francophone)

Laboratoires et entreprises en intelligence artificielle

OpenAI, societe developpant ChatGPT et DALL-E.
Google DeepMind
Anthropic
Meta AI
Inflection AI

Bibliographie
: document utilise comme source pour la redaction de cet article.

Aspects techniques
Stuart J. Russell et Peter Norvig (trad. de l'anglais), Intelligence artificielle [ Artificial Intelligence: A Modern Approach ], Paris, Pearson Education France, 2010, 3e ed., 1198 p. (ISBN 978-2-7440-7455-4, presentation en ligne).
Alan Turing, Jean-Yves Girard, La Machine de Turing, Editions du Seuil, 1995 [detail de ledition], Les Ordinateurs et l'Intelligence, p. 133174.
Claire Remy, L'Intelligence artificielle, Paris, Editions Dunod, 1994, 158 p. (ISBN 2-10-002258-X).
Jean-Marc Alliot et Thomas Schiex, Intelligence artificielle et informatique theorique, Toulouse, CEPADUES, 2002, 543 p. (ISBN 2-85428-578-6).
(en) Michael R. Genesereth et Nils J. Nilsson, Logical Foundations of Artificial Intelligence, Los Altos, Californie, Etats-Unis, Morgan Kaufmann, 1987, 405 p. [detail de ledition] (ISBN 0-934613-31-1).
Jean-Louis Lauriere, Intelligence Artificielle, Eyrolles, 1986.
Jean-Paul Delahaye, Outils logiques pour l'intelligence artificielle, Eyrolles, 1985 [detail des editions] (ISBN 978-2212084122).
Jean-Paul Haton, Marie-Christine Haton, L'Intelligence Artificielle, Paris, Que sais-je ?, 1990, 127 p. (ISBN 2-13-043164-X).
(en) Kate Crawford, Atlas of AI : Power, Politics, and the Planetary Costs of Artificial Intelligence, Yale University Press, 2021.
(en) Jacques Pitrat Artificial Beings, the conscience of a conscious machine, Artificial Beings, the conscience of a conscious machine, ISTE-Wiley, 2019 (ISBN 9781848211018).

Aspects prospectifs
Etude : CGET (2019) Intelligence artificielle  Etat de l'art et perspectives pour la France ; 21 fevrier 2019. URL:https://cget.gouv.fr/ressources/publications/intelligence-artificielle-etat-de-l-art-et-perspectives-pour-la-france  (ISBN 978-2-11-152634-1)  (ISSN 2491-0058).
 Jusqu'ou ira l'intelligence artificielle ? , Pour la science, hors-serie no 115, mai-juin 2022, p. 4-119.

Aspects philosophiques
Marie David et Cedric Sauviat, Intelligence artificielle, la nouvelle barbarie, Editions du Rocher, 2019, 313 p.
Laurent Alexandre, La Guerre des intelligences. Intelligence artificielle versus intelligence humaine, Paris, Editions Jean-Claude Lattes, 2017, 250 p. (ISBN 978-2-7096-6084-6, lire en ligne).
Gilbert Boss, Les machines a penser : L'homme et l'ordinateur, Zurich, Editions du Grand midi, 1987, 202 p. (ISBN 2-88093-105-3).
Jacques Bolo, Philosophie contre intelligence artificielle, Paris, Lingua Franca, 1996, 375 p. (ISBN 2-912059-00-3).
Alan Ross Anderson (trad. de l'anglais), Pensee et machine, Seyssel, Editions Champ Vallon, 1983 (reimpr. 1993), 150 p. (ISBN 2-903528-28-4, lire en ligne).
Jean Sallantin et Jean-Jacques Szczeciniarz, Le Concept de preuve a la lumiere de l'intelligence artificielle, Paris, Presses universitaires de France, 1999, 370 p. (ISBN 2-13-050104-4).
Jean-Gabriel Ganascia, L'Ame-machine, les enjeux de l'intelligence artificielle, Paris, Editions du Seuil, Collection Science Ouverte, 1990, 284 p. (ISBN 2-02-011470-4).
Nick Bostrom, Superintelligence : Paths, Dangers, Strategies, 2014, 328 p. (ISBN 978-0-19-967811-2, lire en ligne).

Aspects economiques
(en) Daron Acemolu  Equality Debate: Power and Progress, with Daron Acemoglu  (8 novembre 2023)  (lire en ligne ) World Inequality Lab,  (visioconference, 6 novembre 2023).
(en) Daron Acemolu et Simon Johnson, Power and Progress : Our Thousand-Year Struggle Over Technology and Prosperity, Basic Books, 2023, 560 p. (ISBN 978-1399804462).
(en) Daron Acemolu,  The Simple Macroeconomics of AI , Economic Policy, Massachusetts Institute of Technology, 5 avril 2024 (lire en ligne  [PDF]).
Abhijit Banerjee et Esther Duflo (trad. Christophe Jacquet), chap. 7  Le piano mecanique , dans Economie utile pour des temps difficiles, Editions du Seuil, 2020.
(en) Joseph Briggs et Devesh Kodnani,  The Potentially Large Effects of Artificial Intelligence on Economic Growth , Global Economics Analyst, Goldman Sachs, 26 mars 2023 (lire en ligne ).
(en) Mauro Cazzaniga, Florence Jaumotte, Longji Li, Giovanni Melina, Augustus Panton, Carlo Pizzinelli, Emma Rockall et Marina Tavares,  Gen-AI: Artificial Intelligence and the Future of Work   [PDF], sur Fonds monetaire international, 14 janvier 2024.
(en) Michael Chui, James Manyika et Mehdi Miremadi,  Four fundamentals of workplace automation  , sur McKinsey, 1er novembre 2015.
Kristalina Georgieva,  LIA transformera leconomie mondiale. Faisons en sorte que lhumanite y soit gagnante , Fonds monetaire international, 14 janvier 2024 (lire en ligne ).
(en) Joel Mokyr,  Secular stagnation? Not in your life , VoxEU Column, Centre for Economic Policy Research, 11 aout 2014 (lire en ligne ).

Fondements cognitifs, psychologiques et biologiques
Herve Chaudet et Liliane Pellegrin, Intelligence artificielle et psychologie cognitive, Paris, Editions Dunod, 1998, 179 p. (ISBN 2-10-002989-4).

Aspects linguistiques
Gerard Sabah, L'Intelligence artificielle et le langage, Representations des connaissances, Processus de comprehension, vol. 1, Hermes, 1989, 768 p. (ISBN 2-86601-134-1).
Gerard Sabah, L'Intelligence artificielle et le langage, Representations des connaissances, Processus de comprehension, vol. 2, Paris, Hermes, 1990, 768 p. (ISBN 2-86601-187-2).
Gerard Sabah, Comprehension des langues et interaction (Traite IC2, Serie Cognition et Traitement de l'Information), Paris, Hermes science: Lavoisier, 2006, 400 p. (ISBN 2-7462-1256-0).
(en) Krzysztof Wok, Machine learning in translation corpora processing, Boca Raton, FL, Taylor & Francis, 2019, 264 p. (ISBN 978-0-367-18673-9)

Histoire
Daniel Crevier et Nathalie Bukcek (trad. de l'anglais), A la recherche de l'intelligence artificielle, Paris, Flammarion, 1997, 438 p. (ISBN 2-08-081428-1) (traduction de (en) The Tumultuous history of the search for artiticial intelligence).
Yuval Noah Harari, Nexus. Une breve histoire des reseaux d'information de l'age de pierre a l'IA., Albin Michel, 2024, 567 p. (ISBN 978-2-226-49488-7).

Vulgarisation
Gerard Tisseau et Jacques Pitrat, Intelligence artificielle : problemes et methodes, Paris, Presses universitaires de France, 1996, 255 p. (ISBN 2-13-047429-2).
Jack Challoner (trad. de l'anglais), L'Intelligence artificielle : Un guide d'initiation au futur de l'informatique et de la robotique, Paris, Pearson Education, 2003, 72 p. (ISBN 2-7440-1600-4).
Hugues Bersini, De l'intelligence humaine a l'intelligence artificielle, Paris, Ellipse, 2006, 192 p. (ISBN 2-7298-2813-3).
Jean-Gabriel Ganascia, L'Intelligence artificielle, Paris, Editions du Cavalier bleu, coll.  Idees recues , 2007, 127 p. (ISBN 978-2-84670-165-5).
Howard Selina (illustrations) et Henry Brighton (texte) (trad. de l'anglais), L'Intelligence artificielle en images, Les Ulis, EDP Sciences, coll.  Apercu , 2015, 176 p. (ISBN 978-2-7598-1772-6).
Marion Montaigne (dessin) et Jean-Noel Lafargue (scenario), L'Intelligence artificielle : fantasmes et realites, Bruxelles, Le Lombard, coll.  La petite bedetheque des savoirs , 2016, 72 p. (ISBN 978-2-8036-3638-9).
Arnold Zephir (scenariste), FibreTigre (scenariste) et Heloise Chochois, Intelligences Artificielles : Miroirs de nos vies, Delcourt, coll.  Octopus , 6 mars 2019 (ISBN 978-2413013143)
L'IA et l'efficacite, dans L'IA et moi sur Savoir media (2021, 30 minutes), consulte le 31 mai 2022

Politique, relations internationales
Daniel Ventre, Intelligence artificielle, cybersecurite et cyberdefense, Londres, ISTE, 2020, 246 p. (ISBN 978-1-78405-679-7 et 978-1-78406-679-6, SUDOC 248481614, presentation en ligne).

Liens externes
 IA militaire : drones de guerre , La Science, CQFD, France Culture, 25 juin 2024.
 Intelligence artificielle , publications en ligne, Interstices, INRIA.
(en) European Association for Artificial Intelligence (EurAI) (Association europeenne pour l'intelligence artificielle)
Association francaise pour l'intelligence artificielle (AfIA).
GdrIA, groupement de recherche du CNRS sur les aspects formels et algorithmiques de l'intelligence artificielle.
Dossier sur l'Intelligence artificielle, savoirs.ens.fr (conferences), Ecole normale superieure.
Sebastien Konieczny,  L'intelligence artificielle, menace ou avancee ? , Huffington Post, 9 mars 2016
 Intelligence artificielle : en mon ame et conscience , La Science, CQFD, France Culture, 1er juin 2023.
William Audureau,  Tout comprendre a lintelligence artificielle, cette technologie source de nombreux malentendus , sur Les Decodeurs, Le Monde, 20 avril 2024

Bases de donnees et dictionnaires

Ressources relatives a la recherche : Internet Encyclopedia of Philosophy Stanford Encyclopedia of Philosophy 
Ressource relative a la sante : Medical Subject Headings 
Ressource relative a l'audiovisuel : France 24  

 Portail de lintelligence artificielle   Portail de linformatique   Portail de la robotique   Portail de la science-fiction   Portail du jeu video   Portail de leconomie   Portail de la philosophie