L'apprentissage automatique, (en anglais : machine learning, litt.  apprentissage machine, ), apprentissage artificiel ou apprentissage statistique est un  champ d'etude de l'intelligence artificielle qui se fonde sur des approches mathematiques et statistiques pour donner aux ordinateurs la capacite d' apprendre  a partir de donnees, c'est-a-dire d'ameliorer leurs performances a resoudre des taches sans etre explicitement programmes pour chacune. Plus largement, il concerne la conception, l'analyse, l'optimisation, le developpement et l'implementation de telles methodes. On parle d'apprentissage statistique car l'apprentissage consiste a creer un modele dont l'erreur statistique moyenne est la plus faible possible.
L'apprentissage automatique comporte generalement deux phases. La premiere consiste a estimer un modele a partir de donnees, appelees observations, qui sont disponibles et en nombre fini, lors de la phase de conception du systeme. L'estimation du modele consiste a resoudre une tache pratique, telle que traduire un discours, estimer une densite de probabilite, reconnaitre la presence d'un chat dans une photographie ou participer a la conduite d'un vehicule autonome. Cette phase dite  d'apprentissage  ou  d'entrainement  est generalement prealable a l'utilisation pratique du modele. La seconde phase est la mise en production : le modele etant determine, de nouvelles donnees peuvent alors etre soumises afin d'obtenir le resultat correspondant a la tache souhaitee. 
Certains systemes peuvent continuer a apprendre une fois en production, s'ils disposent d'un retour sur la qualite des resultats produits. C'est l'apprentissage en ligne, ou l'apprentissage continu.
Selon le type de donnees utilisees pour l'apprentissage, on distingue :

l'apprentissage supervise : l'algorithme apprend a partir de donnees etiquetees (la reponse a la tache, qui est la donnee de sortie, est donc connue pour chaque donnees d'entree). L'objectif est de predire les sorties pour de nouvelles donnees ;
l'apprentissage non supervise : l'algorithme apprend a partir de donnees non etiquetees. Il cherche a decouvrir des structures sous-jacentes, cachees (qui peuvent par exemple etre une densite de probabilite) ; des motifs dans les donnees permettent la classification ou le classement des donnees ;
l'apprentissage semi-supervise : il tire parti d'une grande quantite de donnees non etiquetees pour ameliorer la performance du modele, tout en utilisant une moindre quantite de donnees etiquetees pour guider son apprentissage. Il diminue les couts d'etiquetage manuel des donnees ;
l'apprentissage auto-supervise : c'est une forme d'apprentissage non supervise, ou le modele genere ses propres etiquettes a partir des donnees brutes. Le modele peut ainsi creer des representations internes utiles, sans necessiter de donnees etiquetees manuellement.
L'apprentissage automatique peut etre applique a divers types de donnees, tels des graphes, des arbres, des courbes, ou plus simplement des vecteurs de caracteristiques, qui peuvent etre des variables qualitatives ou quantitatives continues ou discretes.
Si le modele apprend de maniere incrementale, en fonction d'une recompense recue par le programme pour chacune des actions entreprises, on parle d'apprentissage par renforcement.

Historique
Depuis l'antiquite, le sujet des machines pensantes preoccupe les esprits. Ce concept est la base de pensees pour ce qui deviendra ensuite l'intelligence artificielle, ainsi qu'une de ses sous-branches : l'apprentissage automatique.
La concretisation de cette idee est principalement due a Alan Turing (mathematicien et cryptologue britannique) et a son concept de la  machine universelle  en 1936, qui est a la base des ordinateurs d'aujourd'hui. Il continuera a poser les bases de l'apprentissage automatique, avec son article sur  L'ordinateur et l'intelligence  en 1950, dans lequel il developpe, entre autres, le test de Turing.
En 1943, le neurophysiologiste Warren McCulloch et le mathematicien Walter Pitts publient un article decrivant le fonctionnement de neurones en les representant a l'aide de circuits electriques. Cette representation sera la base theorique des reseaux neuronaux.
Arthur Samuel, informaticien americain pionnier dans le secteur de l'intelligence artificielle, est le premier a faire usage de l'expression machine learning (en francais,  apprentissage automatique ) en 1959 a la suite de la creation de son programme pour IBM en 1952. Le programme jouait au Jeu de Dames et s'ameliorait en jouant. A terme, il parvint a battre le 4e meilleur joueur des Etats-Unis,.
Une avancee majeure dans le secteur de l'intelligence machine est le succes de l'ordinateur developpe par IBM, Deep Blue, qui est le premier a vaincre le champion mondial d'echecs Garry Kasparov en 1997. Le projet Deep Blue en inspirera nombre d'autres dans le cadre de l'intelligence artificielle, particulierement un autre grand defi : IBM Watson, l'ordinateur dont le but est de gagner au jeu Jeopardy!. Ce but est atteint en 2011, quand Watson gagne a Jeopardy! en repondant aux questions par traitement de langage naturel.
Durant les annees suivantes, les applications de l'apprentissage automatique mediatisees se succedent bien plus rapidement qu'auparavant.
En 2012, un reseau neuronal developpe par Google parvient a reconnaitre des visages humains ainsi que des chats dans des videos YouTube,.
En 2014, 64 ans apres la prediction d'Alan Turing, le dialogueur Eugene Goostman est le premier a reussir le test de Turing en parvenant a convaincre 33 % des juges humains au bout de cinq minutes de conversation qu'il est non pas un ordinateur, mais un garcon ukrainien de 13 ans.
En 2015, une nouvelle etape importante est atteinte lorsque l'ordinateur  AlphaGo  de Google gagne contre un des meilleurs joueurs au jeu de Go, jeu de plateau considere comme le plus dur du monde.
En 2016, un systeme d'intelligence artificielle a base d'apprentissage automatique nomme LipNet parvient a lire sur les levres avec un grand taux de succes,.

Principes
Les modeles d'apprentissage automatique contiennent des parametres dont les valeurs sont ajustees tout au long de l'apprentissage. La methode de la retropropagation du gradient est capable de detecter, pour chaque parametre, dans quelle mesure il a contribue a une bonne reponse ou a une erreur du modele, et peut l'ajuster en consequence.
L'apprentissage automatique permet a un systeme pilote ou assiste par ordinateur comme un programme, une IA ou un robot, d'adapter ses reponses ou comportements aux situations rencontrees, en se fondant sur l'analyse de donnees empiriques passees issues de bases de donnees, de capteurs, ou du web.
L'apprentissage automatique permet de surmonter la difficulte qui reside dans le fait que l'ensemble de tous les comportements possibles compte tenu de toutes les entrees possibles devient rapidement trop complexe a decrire et programmer de maniere classique (on parle d'explosion combinatoire). On confie donc a des programmes d'apprentissage automatique le soin d'ajuster un modele pour simplifier cette complexite et de l'utiliser de maniere operationnelle. Idealement, l'apprentissage visera a etre non supervise, c'est-a-dire que les reponses aux donnees d'entrainement ne sont pas fournies au modele.
Ces programmes, selon leur degre de perfectionnement, integrent eventuellement des capacites de traitement probabiliste des donnees, d'analyse de donnees issues de capteurs, de reconnaissance (reconnaissance vocale, de forme, d'ecriture), de fouille de donnees, d'informatique theorique

Applications
L'apprentissage automatique est utilise dans un large spectre d'applications pour doter des ordinateurs ou des machines de capacite d'analyser des donnees d'entree comme : perception de leur environnement (vision, Reconnaissance de formes tels des visages, schemas, segmentation d'image, langages naturels, caracteres dactylographies ou manuscrits ; moteurs de recherche, analyse et indexation d'images et de video, en particulier pour la recherche d'image par le contenu ; aide aux diagnostics, medical notamment, bio-informatique, chemoinformatique ; interfaces cerveau-machine ; detection de fraudes a la carte de credit, cybersecurite, analyse financiere, dont analyse du marche boursier ; classification des sequences d'ADN ; jeu ; genie logiciel ; adaptation de sites Web ; robotique (locomotion de robots, etc.) ; analyse predictive dans de nombreux domaines (financiere, medicale, juridique, judiciaire), diminution des temps de calcul pour les simulations informatiques en physique (calcul de structures, de mecanique des fluides, de neutronique, d'astrophysique, de biologie moleculaire, etc.),, optimisation de design dans l'industrie,,, modeles meteorologiques ou predictions de l'ensoleillement dans le developpement des energies solaires ,etc.
Exemples :

un systeme d'apprentissage automatique peut permettre a un robot ayant la capacite de bouger ses membres, mais ne sachant initialement rien de la coordination des mouvements permettant la marche, d'apprendre a marcher. Le robot commencera par effectuer des mouvements aleatoires, puis, en selectionnant et privilegiant les mouvements lui permettant d'avancer, mettra peu a peu en place une marche de plus en plus efficace[ref. necessaire] ;
la reconnaissance de caracteres manuscrits est une tache complexe car deux caracteres similaires ne sont jamais exactement identiques. Il existe des systemes d'apprentissage automatique qui apprennent a reconnaitre des caracteres en observant des  exemples , c'est-a-dire des caracteres connus. Un des premiers systeme de ce type est celui de reconnaissance des codes postaux US manuscrits issu des travaux de recherche de Yann Le Cun, un des pionniers du domaine ,, et ceux utilises pour la  reconnaissance d'ecriture ou OCR.

Types d'apprentissage
Les algorithmes d'apprentissage peuvent se categoriser selon le mode d'apprentissage qu'ils emploient.

Apprentissage supervise
Si les classes sont predeterminees et les exemples connus, le systeme apprend a classer selon un modele de classification ou de classement ; on parle alors d'apprentissage supervise (ou d'analyse discriminante). Un expert (ou oracle) doit prealablement etiqueter des exemples. Le processus se passe en deux phases. Lors de la premiere phase (hors ligne, dite d'apprentissage), il s'agit de determiner un modele a partir des donnees etiquetees. La seconde phase (en ligne, dite de test) consiste a predire l'etiquette d'une nouvelle donnee, connaissant le modele prealablement appris. Parfois il est preferable d'associer une donnee non pas a une classe unique, mais une probabilite d'appartenance a chacune des classes predeterminees ; on parle alors d'apprentissage supervise probabiliste.
Fondamentalement, le machine learning supervise revient a apprendre a une machine a construire une fonction f telle que Y = f(X), Y etant un ou plusieurs resultats d'interet calcule en fonction de donnees d'entrees X effectivement a la disposition de l'utilisateur. Y peut etre une grandeur continue (une temperature par exemple), et on parle alors de regression, ou discrete (une classe, chien ou chat par exemple), et on parle alors de classification.
Des cas d'usage typiques d'apprentissage automatique peuvent etre d'estimer la meteo du lendemain en fonction de celle du jour et des jours precedents, de predire le vote d'un electeur en fonction de certaines donnees economiques et sociales, d'estimer la resistance d'un nouveau materiau en fonction de sa composition, de determiner la presence ou non d'un objet dans une image. L'analyse discriminante lineaire ou les SVM en sont d'autres exemples typiques. Autre exemple, en fonction de points communs detectes avec les symptomes d'autres patients connus (les exemples), le systeme peut categoriser de nouveaux patients, au vu de leurs analyses medicales, en risque estime de developper telle ou telle maladie.

Apprentissage non supervise
Quand le systeme ou l'operateur ne dispose que d'exemples, mais non d'etiquette, et que le nombre de classes et leur nature n'ont pas ete predeterminees, on parle d'apprentissage non supervise ou clustering en anglais. Aucun expert n'est requis. L'algorithme doit decouvrir par lui-meme la structure plus ou moins cachee des donnees. Le partitionnement de donnees, data clustering en anglais, est un algorithme d'apprentissage non supervise.
Le systeme doit ici  dans l'espace de description (l'ensemble des donnees)  cibler les donnees selon leurs attributs disponibles, pour les classer en groupes homogenes d'exemples. La similarite est generalement calculee selon une fonction de distance entre paires d'exemples. C'est ensuite a l'operateur d'associer ou deduire du sens pour chaque groupe et pour les motifs (patterns en anglais) d'apparition de groupes, ou de groupes de groupes, dans leur  espace . Divers outils mathematiques et logiciels peuvent l'aider. On parle aussi d'analyse des donnees en regression (ajustement d'un modele par une procedure de type moindres carres ou autre optimisation d'une fonction de cout). Si l'approche est probabiliste (c'est-a-dire que chaque exemple, au lieu d'etre classe dans une seule classe, est caracterise par un jeu de probabilites d'appartenance a chacune des classes), on parle alors de  soft clustering  (par opposition au  hard clustering ).
Cette methode est souvent source de serendipite. ex. : Pour un epidemiologiste qui voudrait dans un ensemble assez large de victimes de cancer du foie tenter de faire emerger des hypotheses explicatives, l'ordinateur pourrait differencier differents groupes, que l'epidemiologiste chercherait ensuite a associer a divers facteurs explicatifs, origines geographique, genetique, habitudes ou pratiques de consommation, expositions a divers agents potentiellement ou effectivement toxiques (metaux lourds, toxines telle que l'aflatoxine, etc.).Contrairement a l'apprentissage supervise ou l'apprentissage automatique consiste a trouver une fonction f telle que Y = f(X), ou Y est un resultat connu et objectif (par exemple Y =  presence d'une tumeur  ou  absence de tumeur  en fonction de X = image radiographique), dans l'apprentissage non supervise, on ne dispose pas de valeurs de Y, uniquement de valeurs de X (dans l'exemple precedent, on disposerait uniquement des images radiographiques sans connaissance de la presence ou non d'une tumeur. L'apprentissage non supervise pourrait decouvrir deux "clusters" ou groupes correspondant a "presence" ou "absence" de tumeur, mais les chances de reussite sont moindres que dans le cas supervise ou la machine est orientee sur ce qu'elle doit trouver).
L'apprentissage non supervise est generalement moins performant que l'apprentissage supervise, il evolue dans une zone  grise  ou il n'y a generalement pas de  bonne  ou de  mauvaise  reponse mais simplement des similarites mathematiques discernables ou non. L'apprentissage non supervise presente cependant l'interet de pouvoir travailler sur une base de donnees de X sans qu'il soit necessaire d'avoir des valeurs de Y correspondantes, or les Y sont generalement compliques et/ou couteux a obtenir, alors que les seuls X sont generalement plus simples et moins couteux a obtenir (dans l'exemple des images radiographiques, il est relativement aise d'obtenir de telles images, alors qu'obtenir les images avec le label  presence de tumeur  ou  absence de tumeur  necessite l'intervention longue et couteuse d'un specialiste en imagerie medicale).
L'apprentissage non supervise permet potentiellement de detecter des anomalies dans une base de donnees, comme des valeurs singulieres ou aberrantes pouvant provenir d'une erreur de saisie ou d'une singularite tres particuliere. Il peut donc s'agir d'un outil interessant pour verifier ou nettoyer une base de donnees.

Apprentissage semi-supervise
Effectue de maniere probabiliste ou non, il vise a faire apparaitre la distribution sous-jacente des exemples dans leur espace de description. Il est mis en uvre quand des donnees (ou  etiquettes ) manquent Le modele doit utiliser des exemples non etiquetes pouvant neanmoins renseigner. Par exemple, en medecine, il peut constituer une aide au diagnostic ou au choix des moyens les moins onereux de tests de diagnostic.

Apprentissage partiellement supervise
Probabiliste ou non, quand l'etiquetage des donnees est partiel. C'est le cas quand un modele enonce qu'une donnee n'appartient pas a une classe A, mais peut-etre a une classe B ou C (A, B et C etant trois maladies par exemple evoquees dans le cadre d'un diagnostic differentiel).

Apprentissage auto-supervise
L'apprentissage auto-supervise consiste a construire un probleme d'apprentissage supervise a partir d'un probleme non supervise a l'origine.
Pour rappel, l'apprentissage supervise consiste a construire une fonction Y = f(X) et necessite donc une base de donnees ou l'on possede des Y en fonction des X (par exemple, en fonction du texte X correspondant a la critique d'un film, retrouver la valeur du Y correspondant a la note attribuee au film), alors que dans l'apprentissage non supervise, on dispose uniquement des valeurs de X et pas de valeurs de Y (on disposerait par exemple ici uniquement du texte X correspondant a la critique du film, et pas de la note Y attribuee au film).
L'apprentissage auto-supervise consiste donc a creer des Y a partir des X pour passer a un apprentissage supervise, en "masquant" des X pour en faire des Y. Dans le cas d'une image, l'apprentissage auto-supervise peut consister a reconstruire la partie manquante d'une image qui aurait ete tronquee. Dans le cas du langage, lorsqu'on dispose d'un ensemble de phrases qui correspondent aux X sans cible Y particuliere, l'apprentissage auto-supervise consiste a supprimer certains X (certains mots) pour en faire des Y. L'apprentissage auto-supervise revient alors pour la machine a essayer de reconstruire un mot ou un ensemble de mots manquants en fonction des mots precedents et/ou suivants, en une forme d'auto-completion. Cette approche permet potentiellement a une machine de  comprendre  le langage humain, son sens semantique et symbolique. Les modeles IA de langage comme BERT ou GPT-3 sont concus selon ce principe. Dans le cas d'un film, l'apprentissage auto-supervise consisterait a essayer de predire les images suivantes en fonction des images precedentes, et donc a tenter de predire  l'avenir  sur la base de la logique probable du monde reel.
Certains chercheurs, comme Yann Le Cun, pensent que si l'IA generale est possible, c'est probablement par une approche de type auto-supervise qu'elle pourrait etre concue, par exemple en etant immergee dans le monde reel pour essayer a chaque instant de predire les images et les sons les plus probables a venir, en comprenant qu'un ballon en train de rebondir et de rouler va encore continuer a rebondir et a rouler, mais de moins en moins haut et de moins en moins vite jusqu'a s'arreter, et qu'un obstacle est de nature a arreter le ballon ou a modifier sa trajectoire, ou a essayer de predire les prochains mots qu'une personne est susceptible de prononcer ou le prochain geste qu'elle pourrait accomplir. L'apprentissage auto-supervise dans le monde reel serait une facon d'apprendre a une machine le sens commun, le bon sens, la realite du monde physique qui l'entoure, et permettrait potentiellement d'atteindre une certaine forme de conscience. Il ne s'agit evidemment que d'une hypothese de travail, la nature exacte de la conscience, son fonctionnement et sa definition meme restant un domaine actif de recherche.

Apprentissage par renforcement
L'algorithme apprend un comportement etant donne une observation. L'algorithme interagit avec un environnement dynamique dans lequel il doit atteindre un certain but et apprendre a identifier le comportement le plus efficace dans l'environnement considere.
Par exemple, l'algorithme de Q-learning est un exemple classique.
L'apprentissage par renforcement peut aussi etre vu comme une forme d'apprentissage auto-supervise. Dans un probleme d'apprentissage par renforcement, il n'y a en effet a l'origine pas de donnees de sorties Y, ni meme de donnees d'entree X, pour construire une fonction Y = f(X). Il y a simplement un  ecosysteme  muni de regles qui doivent etre respectees, et un  objectif  a atteindre. Par exemple, pour le football, il y a des regles du jeu a respecter et des buts a marquer. Dans l'apprentissage par renforcement, le modele cree lui-meme sa base de donnees en  jouant  (d'ou le concept d'auto-supervise) : il teste des combinaisons de donnees d'entree X et il en decoule un resultat Y qui est evalue ; s'il est conforme aux regles du jeu et atteint son objectif, le modele est recompense et sa strategie est ainsi validee, sinon le modele est penalise. Par exemple pour le football, dans une situation du type  ballon possede, joueur adverse en face, but a 20 metres , une strategie peut etre de  tirer  ou de  dribbler , et en fonction du resultat ( but marque ,  but rate , ou  balle toujours possedee, joueur adverse franchi ), le modele apprend de maniere incrementale comment se comporter au mieux en fonction des situations rencontrees.

Apprentissage par transfert
L'apprentissage par transfert peut etre vu comme la capacite d'un systeme a reconnaitre et a appliquer des connaissances et des competences, apprises a partir de taches anterieures, sur de nouvelles taches ou domaines partageant des similitudes. Il s'agit d'identifier les similitudes entre la ou les tache(s) cible(s) et la ou les tache(s) source(s), puis de transferer la connaissance de la ou des tache(s) source(s) vers la ou les tache(s) cible(s),.
Une application classique de l'apprentissage par transfert est l'analyse d'images. Pour une problematique de classification, l'apprentissage par transfert consiste a repartir d'un modele existant plutot que de repartir de zero. Si par exemple on dispose deja d'un modele capable de reperer un chat parmi tout autre objet du quotidien, et que l'on souhaite classifier les chats par races, il est possible que reentrainer partiellement le modele existant permette d'obtenir de meilleures performances et a moindre cout qu'en repartant de zero,. Un modele souvent utilise pour realiser un apprentissage par transfert de ce type est VGG-16, un reseau de neurones concu par l'Universite d'Oxford, entraine sur ~14 millions d'images, capable de classer avec ~93% de precision mille objets du quotidien.

Algorithmes utilises
Les algorithmes se classent en quatre familles ou types principaux :

regression
classification
partitionnement de donnees
reduction de dimensions.
Plus precisement :

la regression lineaire ;
la regression logistique ;
les machines a vecteur de support ;
les reseaux de neurones, dont les methodes d'apprentissage profond (deep learning en anglais) pour un apprentissage supervise ou non-supervise ;
la methode des k plus proches voisins pour un apprentissage supervise ;
les arbres de decision, methodes a l'origine des Random Forest, par extension egalement du boosting (notamment XGBoost) ;
les methodes statistiques comme le modele de mixture gaussienne ;
l'analyse discriminante lineaire ;
les algorithmes genetiques et la programmation genetique ;
le boosting ;
le bagging.
Ces methodes sont souvent combinees pour obtenir diverses variantes d'apprentissage. Le choix d'un algorithme depend fortement de la tache a resoudre (classification, estimation de valeurs), du volume et de la nature des donnees. Ces modeles reposent souvent sur des modeles statistiques.

Facteurs de pertinence et d'efficacite
La qualite de l'apprentissage et de l'analyse dependent du besoin en amont et a priori de la competence de l'operateur pour preparer l'analyse. Elle depend aussi de la complexite du modele (specifique ou generaliste), de son adequation et de son adaptation au sujet a traiter. In fine, la qualite du travail dependra aussi du mode (de mise en evidence visuelle) des resultats pour l'utilisateur final (un resultat pertinent pourrait etre cache dans un schema trop complexe, ou mal mis en evidence par une representation graphique inappropriee).
Avant cela, la qualite du travail dependra de facteurs initiaux contraignants, liees a la base de donnees :

nombre d'exemples (moins il y en a, plus l'analyse est difficile, mais plus il y en a, plus le besoin de memoire informatique est eleve et plus longue est l'analyse) ;
nombre et qualite des attributs decrivant ces exemples. La distance entre deux  exemples  numeriques (prix, taille, poids, intensite lumineuse, intensite de bruit, etc.) est facile a etablir, celle entre deux attributs categoriels (couleur, beaute, utilite) est plus delicate ;
pourcentage de donnees renseignees et manquantes ;
bruit : le nombre et la  localisation  des valeurs douteuses (erreurs potentielles, valeurs aberrantes) ou naturellement non-conformes au pattern de distribution generale des  exemples  sur leur espace de distribution impacteront sur la qualite de l'analyse.

Etapes d'un projet d'apprentissage automatique
L'apprentissage automatique ne se resume pas a un ensemble d'algorithmes, mais suit une succession d'etapes,.

Definir le probleme a resoudre.
Acquerir des donnees : l'algorithme se nourrissant des donnees en entree, c'est une etape importante. Il y va de la reussite du projet, de recolter des donnees pertinentes et en quantite et qualite suffisantes, et en evitant tout biais dans leur representativite.
Analyser et explorer les donnees. L'exploration des donnees peut reveler des donnees d'entree ou de sortie desequilibrees pouvant necessiter un reequilibrage, le machine learning non supervise peut reveler des clusters qu'il pourrait etre utile de traiter separement ou encore detecter des anomalies qu'il pourrait etre utile de supprimer.
Preparer et nettoyer les donnees : les donnees recueillies doivent etre retouchees avant utilisation. En effet, certains attributs sont inutiles, d'autre doivent etre modifies afin d'etre compris par l'algorithme (les variables qualitatives doivent etre encodees-binarisees), et certains elements sont inutilisables car leurs donnees sont incompletes (les valeurs manquantes doivent etre gerees, par exemple par simple suppression des exemples comportant des variables manquantes, ou par remplissage par la mediane, voire par apprentissage automatique). Plusieurs techniques telles que la visualisation de donnees, la transformation de donnees (en) ou encore la normalisation (variables projetees entre 0 et 1) ou la standardisation (variables centrees - reduites) sont employees afin d'homogeneiser les variables entre elles, notamment pour aider la phase de descente de gradient necessaire a l'apprentissage.
Ingenierie ou extraction de caracteristiques : les attributs peuvent etre combines entre eux pour en creer de nouveaux plus pertinents et efficaces pour l'entrainement du modele. Ainsi, en physique, de la construction de nombres adimensionnels adaptes au probleme, de solutions analytiques approchees, de statistiques pertinentes, de correlations empiriques ou l'extraction de spectres par transformee de Fourier ,. Il s'agit d'ajouter l'expertise humaine au prealable de l'apprentissage machine pour favoriser celui-ci.
Choisir ou construire un modele d'apprentissage : un large choix d'algorithmes existe, et il faut en choisir un adapte au probleme et aux donnees. La metrique optimisee doit etre choisie judicieusement (erreur absolue moyenne, erreur relative moyenne, precision, rappel, etc.)
Entrainer, evaluer et optimiser : l'algorithme d'apprentissage automatique est entraine et valide sur un premier jeu de donnees pour optimiser ses hyperparametres.
Test : puis il est evalue sur un deuxieme ensemble de donnees de test afin de verifier qu'il est efficace avec un jeu de donnee independant des donnees d'entrainement, et pour verifier qu'il ne fasse pas de surapprentissage.
Deployer : le modele est alors deploye en production pour faire des predictions, et potentiellement utiliser les nouvelles donnees en entree pour se re-entrainer et etre ameliore.
Expliquer : determiner quelles sont les variables importantes et comment elles affectent les predictions du modele en general et au cas par cas
La plupart de ces etapes se retrouvent dans les methodes et processus de projet KDD, CRISP-DM et SEMMA, qui concernent les projets d'exploration de donnees.
Toutes ces etapes sont complexes et requierent du temps et de l'expertise, mais il existe des outils permettant de les automatiser au maximum pour "democratiser" l'acces a l'apprentissage automatique. Ces approches sont dites "Auto ML" (pour machine learning automatique) ou "No Code" (pour illustrer que ces approches ne necessitent pas ou tres peu de programmation informatique), elles permettent d'automatiser la construction de modeles d'apprentissage automatique pour limiter au maximum le besoin d'intervention humaine. Parmi ces outils, commerciaux ou non, on peut citer Caret, PyCaret, pSeven, Jarvis, Knime, MLBox ou DataRobot.

Application a la voiture autonome
La voiture autonome parait en 2016 realisable grace a l'apprentissage automatique et les enormes quantites de donnees generees par la flotte automobile, de plus en plus connectee. Contrairement aux algorithmes classiques (qui suivent un ensemble de regles predeterminees), l'apprentissage automatique apprend ses propres regles.
Les principaux innovateurs dans le domaine insistent sur le fait que le progres provient de l'automatisation des processus. Ceci presente le defaut que le processus d'apprentissage automatique devient privatise et obscur. Privatise, car les algorithmes d'AA constituent des gigantesques opportunites economiques, et obscurs car leur comprehension passe derriere leur optimisation. Cette evolution peut potentiellement nuire a la confiance du public envers l'apprentissage automatique, mais surtout au potentiel a long terme de techniques tres prometteuses.
La voiture autonome presente un cadre test pour confronter l'apprentissage automatique a la societe. En effet, ce n'est pas seulement l'algorithme qui se forme a la circulation routiere et ses regles, mais aussi l'inverse. Le principe de responsabilite est remis en cause par l'apprentissage automatique, car l'algorithme n'est plus ecrit mais apprend et developpe une sorte d'intuition numerique. Les createurs d'algorithmes ne sont plus en mesure de comprendre les  decisions  prises par leurs algorithmes, ceci par construction mathematique meme de l'algorithme d'apprentissage automatique.
Dans le cas de l'AA et les voitures autonomes, la question de la responsabilite en cas d'accident se pose. La societe doit apporter une reponse a cette question, avec differentes approches possibles. Aux Etats-Unis, il existe la tendance a juger une technologie par la qualite du resultat qu'elle produit, alors qu'en Europe le principe de precaution est applique, et on y a plus tendance a juger une nouvelle technologie par rapport aux precedentes, en evaluant les differences par rapport a ce qui est deja connu. Des processus d'evaluation de risques sont en cours en Europe et aux Etats-Unis.
La question de responsabilite est d'autant plus compliquee que la priorite chez les concepteurs reside en la conception d'un algorithme optimal, et non pas de le comprendre. L'interpretabilite des algorithmes est necessaire pour en comprendre les decisions, notamment lorsque ces decisions ont un impact profond sur la vie des individus. Cette notion d'interpretabilite, c'est-a-dire de la capacite de comprendre pourquoi et comment un algorithme agit, est aussi sujette a interpretation.
La question de l'accessibilite des donnees est sujette a controverse : dans le cas des voitures autonomes, certains defendent l'acces public aux donnees, ce qui permettrait un meilleur apprentissage aux algorithmes et ne concentrerait pas cet  or numerique  dans les mains d'une poignee d'individus, de plus d'autres militent pour la privatisation des donnees au nom du libre marche, sans negliger le fait que des bonnes donnees constituent un avantage competitif et donc economique,.
La question des choix moraux lies aux decisions laissees aux algorithmes d'AA et aux voitures autonomes en cas de situations dangereuses ou mortelles se pose aussi. Par exemple en cas de defaillance des freins du vehicule, et d'accident inevitable, quelles vies sont a sauver en priorite: celle des passagers ou bien celle des pietons traversant la rue ?

Prospective
Dans les annees 2000-2010, l'apprentissage automatique est encore une technologie emergente, mais polyvalente, qui est par nature theoriquement capable d'accelerer le rythme de l'automatisation et de l'autoapprentissage lui-meme. Combine a l'apparition de nouveaux moyens de produire, stocker et faire circuler l'energie, ainsi qu'a l'informatique ubiquiste, il pourrait bouleverser les technologies et la societe comme l'ont fait la machine a vapeur et l'electricite, puis le petrole et l'informatique lors des revolutions industrielles precedentes.
L'apprentissage automatique pourrait generer des innovations et des capacites inattendues, mais avec un risque selon certains observateurs de perte de maitrise de la part des humains sur de nombreuses taches qu'ils ne pourront plus comprendre et qui seront faites en routine par des entites informatiques et robotisees. Ceci laisse envisager des impacts specifiques complexes et encore impossibles a evaluer sur l'emploi, le travail et plus largement l'economie et les inegalites. Selon le journal Science fin 2017 :  Les effets sur l'emploi sont plus complexes que la simple question du remplacement et des substitutions soulignees par certains. Bien que les effets economiques du BA soient relativement limites aujourd'hui et que nous ne soyons pas confrontes a une  fin du travail  imminente comme cela est parfois proclame, les implications pour l'economie et la main-d'uvre sont profondes .
Il est tentant de s'inspirer des etres vivants sans les copier naivement pour concevoir des machines capables d'apprendre. Les notions de percept et de concept comme phenomenes neuronaux physiques ont d'ailleurs ete popularises dans le monde francophone par Jean-Pierre Changeux. L'apprentissage automatique reste avant tout un sous-domaine de l'informatique, mais il est etroitement lie operationnellement aux sciences cognitives, aux neurosciences, a la biologie et a la psychologie, et pourrait a la croisee de ces domaines, nanotechnologies, biotechnologies, informatique et sciences cognitives, aboutir a des systemes d'intelligence artificielle ayant une assise plus vaste. Des enseignements publics ont notamment ete dispenses au College de France, l'un par Stanislas Dehaene oriente sur l'aspect bayesien des neurosciences, et l'autre par  Yann Le Cun sur les aspects theoriques et pratiques de l'apprentissage profond.

Enjeux et limites
Quantite et qualite des donnees
L'apprentissage automatique demande de grandes quantites de donnees pour fonctionner correctement. Il est impossible de savoir a priori quelle taille la base de donnees doit avoir pour que l'apprentissage automatique fonctionne correctement, en fonction de la complexite de la problematique etudiee et de la qualite des donnees, mais un ordre de grandeur assez usuel est que, pour une problematique de regression ou de classification basee sur des donnees tabulaires, il faut dix fois plus d'exemples dans la base de donnees que de variables d'entrees du probleme (degres de liberte),. Pour des problematiques complexes, il est possible qu'il faille plutot cent a mille fois plus d'exemples que de degres de liberte. Pour de la classification d'images, en partant de zero, il est usuellement necessaire d'avoir ~1000 images par classe, ou ~100 images par classe si on realise de l'apprentissage par transfert depuis un modele existant plutot que de partir de zero,.
La qualite des donnees se traduit par leur richesse et leur equilibre statistique, leur completude (pas de valeurs manquantes), ainsi que leur precision (incertitudes faibles).
Il peut s'averer difficile de controler l'integrite des jeux de donnees, notamment dans le cas de donnees generees par les reseaux sociaux.
La qualite des  decisions  prises par un algorithme d'AA depend non seulement de la qualite (donc de leur homogeneite, fiabilite, etc.) des donnees utilisees pour lentrainement mais surtout de leur quantite. Donc, pour un jeu de donnees sociales collecte sans attention particuliere a la representation des minorites, l'AA est statistiquement injuste vis-a-vis de celles-ci. En effet, la capacite a prendre de  bonnes  decisions depend de la taille des donnees, or celle-ci sera proportionnellement inferieure pour les minorites. Il convient donc de realiser l'apprentissage automatique avec des donnees les plus equilibrees possibles, quitte a passer par un pre-traitement des donnees afin de retablir l'equilibre ou par une modification/penalisation de la fonction objectif.
L'AA ne distingue actuellement pas cause et correlation de par sa construction mathematique : usuellement, ce sont des causalites qui sont recherchees par l'utilisateur, mais l'AA ne peut trouver que des correlations. Il incombe a l'utilisateur de verifier la nature du lien mis en lumiere par l'AA, causal ou non. Plusieurs variables correlees peuvent etre liees causalement a une autre variable cachee qu'il peut etre utile d'identifier.
Mathematiquement, certaines methodes d'AA, notamment les methodes a base d'arbres comme les arbres de decision, les forets aleatoires ou les methodes de boosting, sont incapables d'extrapoler (produire des resultats en dehors du domaine connu). D'autres methodes d'AA, comme les modeles polynomiaux ou les reseaux de neurones, sont mathematiquement tout a fait capables de produire des resultats en extrapolation. Ces resultats en extrapolation peuvent ne pas etre fiables du tout (c'est typiquement le cas pour les modeles polynomiaux) mais peuvent egalement etre relativement corrects, au moins qualitativement, si l'extrapolation n'est pas exagerement grande (reseaux de neurones notamment). En "grandes" dimensions (a partir de ~100 variables), toute nouvelle prediction doit de toute facon tres probablement etre consideree comme de l'extrapolation.
L'utilisation d'algorithmes d'apprentissage automatique demande donc d'avoir conscience du cadre de donnees que l'on a utilise pour l'apprentissage lors de leur utilisation. Il est donc pretentieux d'attribuer des vertus trop grandes aux algorithmes d'apprentissage automatique.

Biais des algorithmes et des donnees
Un algorithme peut etre biaise lorsque son resultat devie par rapport a un resultat neutre, loyal ou equitable. Dans certains cas, les biais algorithmiques peuvent conduire a des situations de discrimination.
Les donnees peuvent aussi etre biaisees, si l'echantillon de donnees utilisees pour l'apprentissage du modele n'est pas neutre et representatif de la realite ou desequilibre. Ce biais est alors appris et reproduit par le modele,.
Cette notion de biais est si importante qu'elle est traitee clairement depuis 2018 dans quatre des sept exigences clefs sur l'intelligence artificielle digne de confiance ( Respect de la vie privee et gouvernance des donnees ,  Transparence ,  Diversite, non-discrimination et equite  et  Responsabilite ) issues des travaux de reference des experts de la Commission europeenne, qui preludent a la future reglementation europeenne, l'IA Act.

Explicabilite et explications des decisions
Les algorithmes d'apprentissage automatique posent des problemes d'explicabilite globale du systeme. Si certains modeles comme la regression lineaire ou la regression logistique ont un nombre de parametres limite et peuvent etre interpretes, d'autres types de modele comme les reseaux de neurones artificiels n'ont pas d'interpretation evidente, ce qui fait avancer a de nombreux auteurs que l'apprentissage automatique serait une  boite noire  et poserait ainsi un probleme de confiance. A ce titre, les experts de la Commission europeenne prennent pour position que l'explicabilite est l'un des quatre grands principes fondateurs de leurs lignes directrices en matiere d'ethique pour une intelligence artificielle digne de confiance. En cas d'arbitrage, parce qu'intimement liee aux droits relatifs a la justice, l'explicabilite fait ainsi echo aux notions de tracabilite, d'auditabilite et de responsabilite d'un systeme d'IA de confiance. Historiquement, d'autre types de modeles d'apprentissage ont ete etudier pour palier a ce probleme. Par exemple, les machines d'apprentissage logique, qui sont aujourdhui employees dans des secteurs ou la comprehension et/ou la tracabilite des decisions prises est primordiale: la medecine ,les services financiers et la logistique.
Des outils mathematiques permettent d' auditer  un modele d'apprentissage automatique afin de voir ce qu'il a  compris  et comment il fonctionne.
La feature importance ou  importance des variables  permet de quantifier comment, en moyenne, chacune des variables d'entree du modele affecte chacune de ses variables de sortie et permet de reveler que, par exemple, une variable est majoritaire, ou que certaines variables n'ont aucun impact sur la  decision  du modele. L'importance des variables n'est cependant accessible que pour un ensemble restreint de modeles, comme les modeles lineaires, la regression logistique ou les methodes a base d'arbres comme les arbres de decision, les forets aleatoires ou les methodes de boosting.
Pour les modeles plus complexes comme les reseaux de neurones, on peut recourir a l'analyse de la variance par plan d'experience numerique par Monte Carlo pour calculer les indices de Sobol du modele, qui jouent alors un role similaire a celui de l'importance des variables. L'importance des variables et les indices de Sobol ne renseignent neanmoins que sur l'importance moyenne des variables et ne permettent donc pas aisement d'analyser la  decision  du modele au cas par cas. Ces indicateurs ne renseignent pas non plus sur le poids qualitatif des variables ( telle variable d'entree a la hausse entraine t-elle telle variable de sortie a la hausse, a la baisse, en  cloche , lineairement, avec effet seuil ? ). Pour pallier ces problemes, on peut recourir a la theorie des jeux pour calculer et visualiser les valeurs et les graphes de Shapley, qui permettent d'acceder a une grandeur similaire a l'importance des variables au cas par cas, ainsi que de tracer la reponse d'une variable de sortie en fonction d'une variable d'entree pour voir comment evolue qualitativement la reponse du modele. Enfin, les graphes de dependances partielles permettent egalement de voir comment evolue la reponse moyenne du modele en fonction des variables d'entree (allure qualitative), et permettent egalement de tester le modele en extrapolation pour verifier que son comportement reste un minimum plausible (pas de rupture de pente ou d'effet de seuil, par exemple).
Ces concepts permettent a Christoph Molnar, scientifique des donnees specialise dans l'explicabilite, d'avancer que l'apprentissage automatique n'est pas reellement une boite noire, mais plutot une  boite grise  : il est possible d'avoir une bonne comprehension de ce que fait l'apprentissage automatique, sans que cette comprehension ne puisse cependant etre totalement exhaustive, ni denuee de potentiels effets de bords.

Apprentissage profond
L'apprentissage profond (reseaux de neurones profonds) est une methode d'apprentissage automatique. En pratique, depuis l'amelioration significative des performances de l'apprentissage profond depuis le debut des annees 2010, on distingue communement l'apprentissage automatique  classique  (tout type d'apprentissage automatique comme les modeles lineaires, les methodes a base d'arbres comme le bagging ou le boosting, les processus gaussiens, les machines a vecteur de support ou les splines) de l'apprentissage profond.
Un reseau de neurones comporte toujours au moins trois couches de neurones : couche d'entree, couche "cachee" et couche de sortie. Usuellement, un reseau de neurones n'est considere reellement "profond" que lorsqu'il comporte au moins trois couches cachees, mais cette definition est quelque peu arbitraire et, par abus de langage, on parle souvent d'apprentissage profond meme si un reseau de neurones comporte moins de trois couchees cachees.
Il est generalement admis que l'apprentissage profond domine l'apprentissage automatique dans certains domaines d'application comme l'analyse d'images, de sons ou de textes.
Dans d'autres domaines, ou les bases de donnees sont plus  simples  que des images, des sons ou des corpus de textes, et generalement  tabulaires , l'apprentissage automatique se revele generalement plus performant que l'apprentissage profond lorsque les bases de donnees sont relativement petites (moins de 10 000 exemples) ; au-dela, la superiorite de l'apprentissage automatique se retablit generalement. (Des donnees tabulaires sont des informations formatees en tableaux de donnees[pas clair]regroupant par exemple des indicateurs socio-economiques relatifs a l'emploi, des indicateurs sur les donnees immobilieres a Paris, des marqueurs bio-medicaux relatifs au diabete, des variables sur la composition chimique et la resistance du beton, des donnees decrivant la morphologie de fleurs, etc. Des tableaux de donnees de ce type, qui se pretent bien a l'apprentissage automatique, peuvent par exemple etre trouves sur le Machine Learning Repository de l'Universite de Californie). Certains chercheurs expliquent cette superiorite de l'apprentissage automatique sur l'apprentissage profond dans le cas des "petites" bases de donnees par le fait que les reseaux de neurones sont surtout performants pour trouver des fonctions continues, or beaucoup de fonctions rencontrees avec ces petites bases de donnees tabulaires sont apparemment irregulieres ou discontinues. Une autre explication serait la moins grande robustesse des reseaux de neurones aux variables  non importantes , or il arrive que dans les bases de donnees tabulaires il y ait des dizaines voire des centaines de variables qui n'affectent pas le resultat recherche et que les reseaux de neurones auraient du mal a discriminer. Enfin, une autre explication serait la tres grande force du reseau de neurones qui est sa capacite a rechercher des informations invariantes par position, rotation et echelle (cruciales en analyse d'images), qui deviendrait une faiblesse sur ces petites bases de donnees tabulaires, cette capacite ne presentant alors pas d'utilite. La superiorite de l'apprentissage automatique sur l'apprentissage profond pour ces cas d'usage semble statistiquement averee, mais n'est neanmoins pas absolue, notamment si les bases de donnees ne contiennent pas ou peu de variables non importantes et si les fonctions recherchees sont continues ; c'est notamment le cas pour les modeles de substitution (en) (surrogate model) en simulation numerique en physique,[source insuffisante]. Il convient donc, pour rechercher la methode la plus performante, de tester sans a priori un large eventail d'algorithmes disponibles.
Le temps de calcul pour l'apprentissage des modeles est aussi generalement tres differenciant entre les apprentissages automatique et profond. L'apprentissage automatique est usuellement beaucoup plus rapide a entrainer que l'apprentissage profond (des facteurs 10, 100 ou 1 000 sont possibles), mais lorsque les bases de donnees sont petites, cet avantage n'est plus toujours significatif, les temps de traitement restant raisonnables. Par ailleurs, l'apprentissage automatique est generalement beaucoup moins capable de tirer parti du calcul sur GPU que l'apprentissage profond, or celui-ci a considerablement progresse depuis les annees 2000 et peut etre 10 ou 100 fois plus rapide que le calcul  classique  sur CPU, ce qui peut permettre, avec un materiel adapte, de combler une large part de l'ecart de temps de calcul entre les deux methodes,. 
La superiorite du GPU sur le CPU dans ce contexte s'explique par le fait qu'un GPU est constitue de centaines voire de milliers d'unites de calcul parallele (a comparer aux quelques unites de calcul parallele seulement qui equipent les CPU), or le calcul matriciel, fondement des reseaux de neurones, est massivement parallelisable. Les GPU sont egalement capables d'atteindre des bandes passantes (quantite de donnees traitees par seconde) bien superieures a celles des CPU. Une autre raison tient a la capacite des GPU a realiser des calculs en simple precision (nombre flottant, floating point, sur 32 bits, notes FP32) plus efficacement que les CPU, dont les fonctions sont tres generales et ne sont pas specifiquement optimisees pour un type de precision donne. Certains GPU peuvent etre tres performants en demi-precision (FP16). Or, l'entrainement des reseaux de neurones peut recourir principalement a la simple precision (FP32) voire la demi-precision (FP16), voire une precision mixte (FP32-FP16) ; peu d'applications de calcul scientifique permettent cela, comme la mecanique des fluides numerique, qui requiert generalement de la double precision (FP64).

Dans la litterature
Il existe de nombreuses uvres de science-fiction sur le sujet de l'intelligence artificielle en general et de l'apprentissage automatique en particulier. Le traitement scientifique est generalement peu detaille et quelque peu fantaisiste, mais des auteurs comme Peter Watts approchent le sujet avec un semblant de realisme. Ainsi, dans la trilogie de romans Rifteurs, Peter Watts detaille l'architecture des reseaux de neurones et leurs modes de "raisonnement" et de fonctionnement bases sur l'optimisation de metriques mathematiques et, dans le roman Eriophora, il detaille le fonctionnement d'une IA en parlant de fonctions d'activation sigmoides, d'arbres de decision, de cycles d'apprentissage et d'effet de seuil de convergence.

Notes et references
Voir aussi
Bibliographie
(en) Trevor Hastie, Robert Tibshirani et Jerome Friedman, The Elements of Statistical Learning : Data Mining, Inference, and Prediction, 2009, 2e ed. (lire en ligne)
(en) Christopher M. Bishop, Neural Networks for Pattern Recognition, Oxford University Press, 1995 (ISBN 0-19853-864-2).
(en) Richard O. Duda, Peter E. Hart, David G. Stork, Pattern Classification, Wiley-interscience, 2001 (ISBN 0-471-05669-3) [detail des editions]
Vincent Barra, Antoine Cornuejols, Laurent Miclet, Apprentissage Artificiel : Concepts et algorithmes, Eyrolles, 2021 (ISBN 978-2-416-001-04-8) [detail des editions]
(en) David MacKay, Information Theory, Inference, and Learning Algorithms, Cambridge University Press, 2003 (ISBN 0-521-64298-1) [detail des editions]
(en) Tom M. Mitchell, Machine Learning, 1997 [detail des editions]
(en) Christopher M. Bishop, Pattern Recognition And Machine Learning, Springer, 2006 (ISBN 0-387-31073-8) [detail des editions]
(en) T.-M. Huang, V. Kecman, I. Kopriva (2006), Kernel Based Algorithms for Mining Huge Data Sets, Supervised, Semi-supervised, and Unsupervised Learning, Springer-Verlag, Berlin, Heidelberg, 260 p. 96 illus., Hardcover,  (ISBN 3-54031-681-7) (learning-from-data.com)
(en) Vojislav Kecman (2001), Learning and Soft Computing, Support Vector Machines, Neural Networks and Fuzzy Logic Models, The MIT Press, Cambridge, MA, 608 pp., 268 illus.,  (ISBN 0-26211-255-8) (support-vector.ws)
(en) Sholom Weiss, Casimir Kulikowski (1991). Computer Systems That Learn, Morgan Kaufmann.  (ISBN 1-55860-065-5)
(en) Krzysztof Wok, Machine learning in translation corpora processing, Boca Raton, FL, Taylor & Francis, 2019, 264 p. (ISBN 978-0-367-18673-9)

Articles connexes
Liens externes

Ressource relative a la sante : Medical Subject Headings 
Ressource relative a l'audiovisuel : France 24  

Alain Clapaud, Machine learning : decryptage d'une technologie qui monte, Le Journal du Net, 10 avril 2015
Pirmin Lemberger, Le  machine learning   quand les donnees remplacent les algorithmes, Le Journal du Net, 28 mars 2014.

 Portail de lintelligence artificielle   Portail de linformatique   Portail de l'informatique theorique   Portail des probabilites et de la statistique