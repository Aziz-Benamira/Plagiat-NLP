Deep learning is a subset of machine learning that uses neural networks with multiple layers to perform tasks like classification, regression, and representation learning. Inspired by biological neuroscience, it stacks artificial neurons into layers and trains them to process data. The term "deep" refers to the use of multiple layers, ranging from three to thousands, in the network. Methods can be supervised, semi-supervised, or unsupervised. Popular architectures include fully connected networks, recurrent neural networks, convolutional neural networks, transformers, generative adversarial networks, and deep belief networks. These architectures have been applied to areas like computer vision, natural language processing, speech recognition, medical imaging, drug design, and climate science, often achieving or surpassing human-level performance. Deep learning models transform input data into increasingly abstract representations through hierarchical layers. For example, in image recognition, layers identify features like edges, shapes, and objects. Unlike traditional machine learning, deep learning automates feature discovery rather than relying on manual feature engineering. The depth of transformations, known as the credit assignment path (CAP), enables deep learning to extract better features with CAP depth greater than two. Deep learning architectures are often built incrementally, layer by layer, and can train on unlabeled data, which is more abundant than labeled data. Theoretical foundations include the universal approximation theorem and probabilistic interpretations, which relate to the model's ability to approximate functions and handle uncertainty in data.
Neural networks have been used for implementing language models since the early 2000s. LSTM helped to improve machine translation and language modeling.
Other key techniques in this field are negative sampling and word embedding. Word embedding, such as word2vec, can be thought of as a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a vector space. Using word embedding as an RNN input layer allows the network to parse sentences and phrases using an effective compositional vector grammar. A compositional vector grammar can be thought of as probabilistic context free grammar (PCFG) implemented by an RNN. Recursive auto-encoders built atop word embeddings can assess sentence similarity and detect paraphrasing. Deep neural architectures provide the best results for constituency parsing, sentiment analysis, information retrieval, spoken language understanding, machine translation, contextual entity linking, writing style recognition, named-entity recognition (token classification), text classification, and others.
Recent developments generalize word embedding to sentence embedding.
Google Translate (GT) uses a large end-to-end long short-term memory (LSTM) network. Google Neural Machine Translation (GNMT) uses an example-based machine translation method in which the system "learns from millions of examples". It translates "whole sentences at a time, rather than pieces". Google Translate supports over one hundred languages. The network encodes the "semantics of the sentence rather than simply memorizing phrase-to-phrase translations". GT uses English as an intermediate between most language pairs.